{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps : Automatiser, expérimenter et optimiser les pipelines de Machine Learning\n",
    "\n",
    "Mettre en production des modèles de machine learning peut parfois ressembler à un parcours semé d'embûches. Vous avez peut-être déjà rencontré des problèmes comme des résultats impossibles à reproduire, des difficultés à gérer les versions des modèles, ou encore l'absence d'alertes quand un modèle commence à dériver en production. C'est là qu'intervient le MLOps.\n",
    "\n",
    "#### Qu'est-ce que le MLOps ?\n",
    "\n",
    "Le MLOps (Machine Learning Operations) est une méthode qui emprunte les principes du **DevOps** pour les appliquer aux projets de machine learning. L'objectif ? Simplifier, automatiser et fiabiliser toutes les étapes du cycle de vie d'un modèle.\n",
    "\n",
    "Imaginez un processus où chaque étape, depuis la préparation des données jusqu'à l'entraînement, au déploiement et au suivi est fluide, transparente, et surtout automatisée. Le MLOps vous aide à construire des modèles performants et durables, tout en facilitant l'expérimentation et l'amélioration continue.\n",
    "\n",
    "#### Voici le pipeline classique MLOps avec Github actions:\n",
    "- **data-preprocessing**\n",
    "  - Prétraitement et gestion des données.\n",
    "\n",
    "- **model-training**\n",
    "  - Automatisation des entraînements et sélection des modèles.\n",
    "\n",
    "- **model-validation**\n",
    "  - Validation et tests rigoureux.\n",
    "\n",
    "- **model-deployment**\n",
    "  - Déploiement continu avec monitoring en production.\n",
    "\n",
    "- **model-iteration**\n",
    "  - Amélioration continue : itération en fonction des feedbacks.\n",
    "\n",
    "\n",
    "> **Exemple visuel : Capture d’écran d’un pipeline automatisé dans github.**\n",
    "\n",
    "---\n",
    "\n",
    "## Un Pipeline Structuré et Flexible\n",
    "\n",
    "Un pipeline MLOps combine robustesse et agilité, s'articulant autour des étapes suivantes :\n",
    "\n",
    "- **Initialisation**\n",
    "  - Chargement des configurations (**Hydra**, **DVC**).\n",
    "  - Préparation des données (local, cloud, ou bases de données).\n",
    "  - Tracking des expériences (**MLflow**, **Weights & Biases**).\n",
    "\n",
    "- **Prétraitement des données**\n",
    "  - Nettoyage : gestion des valeurs manquantes et outliers.\n",
    "  - Transformations : encodage, standardisation.\n",
    "\n",
    "- **Sélection et entraînement des modèles**\n",
    "  - Types : des modèles simples (ég. régressions) aux plus complexes (**BERT**).\n",
    "  - Tuning hyperparamétrique (**Optuna**, **GridSearch**).\n",
    "  - Stratégies : validation rapide ou rigoureuse selon le contexte.\n",
    "\n",
    "- **Évaluation finale**\n",
    "  - Comparaison sur un ensemble indépendant.\n",
    "  - Logging des métriques dans **MLflow**.\n",
    "\n",
    "- **Déploiement en production**\n",
    "  - Promotion après validation en **staging**.\n",
    "  - Monitoring actif : latence, dérive des données.\n",
    "\n",
    "> **Exemple visuel : Capture d’écran montrant des runs MLflow avec métriques clés.**\n",
    "\n",
    "---\n",
    "\n",
    "## Pourquoi tester plusieurs modèles et stratégies ?\n",
    "\n",
    "### Scénario concret :\n",
    "Vous travaillez sur un projet d’analyse des avis clients pour un produit. Après quelques expérimentations, votre collègue propose :\n",
    "\n",
    "> \"Pourquoi ne pas tester des modèles plus avancés ? Un modèle simple fonctionne bien ici, mais peut-être qu’un modèle plus élaboré donnerait des insights plus précis, et pourrait aussi s’appliquer à d’autres cas d’usage.\"\n",
    "\n",
    "Curieux, vous décidez de tester différentes approches :\n",
    "\n",
    "1. **Commencer simple** : Vous utilisez une régression pour une validation rapide.\n",
    "2. **Approfondir** : Vous passez à un modèle avancé comme **XGBoost** pour mieux capturer les subtilités.\n",
    "3. **Maximiser les performances** : Vous testez un **BERT** afin de tirer parti de ses capacités sur des textes complexes.\n",
    "\n",
    "Lors des tests, un autre défi apparaît : votre pipeline actuel relance systématiquement toutes les étapes, y compris les plus coûteuses, même lorsque vous ne souhaitez qu’un test rapide. Cela freine vos expérimentations. Alors que vous discutez avec une collègue, elle vous lance :\n",
    "\n",
    "> \"Et si on pouvait choisir la stratégie la plus adaptée à chaque étape ? Par exemple, une validation rapide pour prototyper et une validation rigoureuse pour sélectionner le meilleur modèle.\"\n",
    "\n",
    "Cette idée vous conduit à introduire des **stratégies globales**, permettant d’ajuster le pipeline selon vos besoins.\n",
    "\n",
    "| **Étape/Stratégie**                   | **Validation rapide**             | **Optimisation équilibrée**             | **Validation rigoureuse**             |\n",
    "|-----------------------------------------|------------------------------------|------------------------------------|------------------------------------|\n",
    "| **Découpage des Données**             | 2 ensembles : Train/Test           | 3 ensembles : Train/Validation/Test | Validation croisée (k-folds)       |\n",
    "| **Cas d’usage**                       | Prototypage ou tests exploratoires | Comparaison rigoureuse            | Robustesse avec peu de données     |\n",
    "| **Optimisation**                       | Hyperparamètres par défaut        | Optimisation sur Validation        | Optimisation sur k-folds           |\n",
    "| **Validation**                         | Non applicable                    | Validation explicite              | Intégrée dans k-folds            |\n",
    "| **Promotion**                          | Usage limité                     | Standard en production             | Haute confiance pour production    |\n",
    "\n",
    "Grâce à ces ajustements, votre pipeline devient plus adaptable. Vous pouvez désormais passer rapidement d’un prototype exploratoire à une validation rigoureuse, tout en économisant du temps et des ressources.\n",
    "\n",
    "---\n",
    "\n",
    "## Mettre en Œuvre le MLOps\n",
    "\n",
    "### Outils clés :\n",
    "- **Tracking** : MLflow, Weights & Biases.\n",
    "- **Orchestration CI/CD** : GitHub Actions, Azure DevOps.\n",
    "- **Monitoring** : Azure Application Insights.\n",
    "\n",
    "### Étapes :\n",
    "1. **Initialiser et configurer** : Adoptez des configurations dynamiques avec Hydra ou DVC.\n",
    "2. **Expérimenter** : Logguez les paramètres et métriques pour chaque essai.\n",
    "3. **Valider et déployer** : Passez les modèles par des phases de staging avant la production.\n",
    "\n",
    "> **Exemple visuel : Logs d’Azure Application Insights affichant les dérives des données.**\n",
    "\n",
    "---\n",
    "\n",
    "## Boucle d’Amélioration Continue\n",
    "\n",
    "Le MLOps met en place une boucle vertueuse :\n",
    "\n",
    "1. **Collecte des données réelles** : Enrichir le dataset avec des cas non couverts.\n",
    "2. **Analyse des performances** : Suivre les métriques techniques (latence, précision) et métiers (impact sur les objectifs business).\n",
    "3. **Ajustements** : Tester de nouveaux modèles, ajuster les hyperparamètres ou changer de stratégie.\n",
    "4. **Redéploiement contrôlé** : Évaluer chaque nouvelle version avant production.\n",
    "\n",
    "> **Exemple visuel : Tableau de bord montrant les métriques d’évolution d’un modèle en production.**\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Le MLOps combine **automatisation**, **traçabilité**, et **modularité** pour rendre les pipelines adaptables. En explorant plusieurs stratégies et modèles tout en intégrant un suivi actif des performances, les entreprises peuvent réduire leurs coûts tout en améliorant leurs modèles en continu.\n",
    "\n",
    "Grâce à une approche structurée, le MLOps permet d’accélérer le temps de mise sur le marché et d’augmenter la qualité des modèles, transformant ainsi l’expérimentation en avantage compétitif durable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps : Automatiser, Expérimenter et Optimiser les Pipelines de Machine Learning\n",
    "\n",
    "Les systèmes de **machine learning (ML)** s'appuient sur des pipelines robustes pour garantir des modèles fiables et adaptés. Pourtant, des problèmes récurrents tels que la **réplicabilité**, la **gestion des versions**, et le **monitoring en production** ralentissent souvent leur mise en œuvre efficace. Le **MLOps** offre une approche structurée pour résoudre ces enjeux.\n",
    "\n",
    "### Objectifs du MLOps :\n",
    "- **Automatiser** les étapes essentielles : préparation des données, entraînement, et déploiement.\n",
    "- Garantir une **traçabilité** totale des modèles et des métriques.\n",
    "- Fournir une **flexibilité adaptative** pour tester différents modèles et stratégies.\n",
    "- **Surveiller** et améliorer en continu les performances des modèles en production.\n",
    "\n",
    "---\n",
    "\n",
    "## Pourquoi le MLOps est-il essentiel ?\n",
    "\n",
    "### Cas concret : un pipeline classique inefficace\n",
    "Vous travaillez sur un projet où chaque mise à jour ou ajustement de modèle entraîne le recalcul complet des étapes du pipeline. Par exemple, chaque fois que vous testez un nouveau modèle ou ajustez des hyperparamètres, tout le pipeline se relance, y compris les étapes déjà validées. Cela devient rapidement un obstacle, freinant vos expérimentations et consommant inutilement des ressources.\n",
    "\n",
    "### Problèmes courants :\n",
    "- **Non-reproductibilité** : Résultats difficiles à reproduire.\n",
    "- **Versions non gérées** : Difficulté à suivre les évolutions des modèles et des données.\n",
    "- **Absence de monitoring** : Impossibilité de détecter les dérives des modèles.\n",
    "- **Pipelines rigides** : Expérimentations limitées par une architecture trop figée.\n",
    "\n",
    "### Solutions offertes par le MLOps :\n",
    "- **Automatisation** via des outils comme **GitHub Actions** ou **Azure DevOps**.\n",
    "- **Versionnement** des modèles et des métriques pour une vue d’ensemble claire.\n",
    "- **Monitoring continu** avec **Azure Application Insights**.\n",
    "- **Modularité** pour ajuster les pipelines selon les besoins.\n",
    "\n",
    "> **Exemple visuel : Capture d’écran d’un pipeline automatisé dans Azure DevOps.**\n",
    "\n",
    "---\n",
    "\n",
    "## Un Pipeline Structuré et Flexible\n",
    "\n",
    "Un pipeline MLOps combine robustesse et agilité, s'articulant autour des étapes suivantes :\n",
    "\n",
    "- **Initialisation**\n",
    "  - Chargement des configurations (**Hydra**, **DVC**).\n",
    "  - Préparation des données (local, cloud, ou bases de données).\n",
    "  - Tracking des expériences (**MLflow**, **Weights & Biases**).\n",
    "\n",
    "- **Prétraitement des données**\n",
    "  - Nettoyage : gestion des valeurs manquantes et outliers.\n",
    "  - Transformations : encodage, standardisation.\n",
    "\n",
    "- **Sélection et entraînement des modèles**\n",
    "  - Types : des modèles simples (ég. régressions) aux plus complexes (**BERT**).\n",
    "  - Tuning hyperparamétrique (**Optuna**, **GridSearch**).\n",
    "  - Stratégies : validation rapide ou rigoureuse selon le contexte.\n",
    "\n",
    "- **Évaluation finale**\n",
    "  - Comparaison sur un ensemble indépendant.\n",
    "  - Logging des métriques dans **MLflow**.\n",
    "\n",
    "- **Déploiement en production**\n",
    "  - Promotion après validation en **staging**.\n",
    "  - Monitoring actif : latence, dérive des données.\n",
    "\n",
    "> **Exemple visuel : Capture d’écran montrant des runs MLflow avec métriques clés.**\n",
    "\n",
    "---\n",
    "\n",
    "## Pourquoi tester plusieurs modèles et avoir un pipeline unique ?\n",
    "\n",
    "### Scénario concret :\n",
    "Vous travaillez sur un projet complexe d’analyse des avis clients pour un produit. Après quelques expérimentations, votre collègue propose :\n",
    "\n",
    "> \"Nous devons tester plusieurs modèles, des plus simples aux plus avancés, pour comprendre ce qui fonctionne le mieux. Par exemple, un modèle simple peut suffire pour des cas spécifiques, mais un modèle plus avancé pourrait nous donner des insights plus précis et être applicable à d’autres cas d’usage.\"\n",
    "\n",
    "Ce besoin implique de réaliser de nombreuses expérimentations avec des configurations différentes, mais vous souhaitez éviter de multiplier les pipelines ou d’introduire des conflits avec vos collègues qui travaillent sur d'autres scénarios.\n",
    "\n",
    "Curieux, vous décidez de tester différentes approches :\n",
    "\n",
    "1. **Commencer simple** : Vous utilisez une régression pour une validation rapide.\n",
    "2. **Approfondir** : Vous passez à un modèle avancé comme **XGBoost** pour mieux capturer les subtilités.\n",
    "3. **Maximiser les performances** : Vous testez un **BERT** afin de tirer parti de ses capacités sur des textes complexes.\n",
    "\n",
    "Ces expérimentations révèlent une autre problématique : votre pipeline actuel est utilisé par plusieurs collègues aux besoins différents. L’un souhaite tester rapidement des idées avec des validations rapides, tandis que l’autre travaille sur des validations approfondies nécessitant plus de ressources. Les ajustements constants dans le pipeline causent des conflits et ralentissent vos progrès collectifs.\n",
    "\n",
    "Alors que vous discutez ensemble, l'un d'eux suggère :\n",
    "\n",
    "> \"Et si on séparait la configuration du code du pipeline ? On pourrait créer un système où les scénarios spécifiques sont configurables avec Hydra. Cela éviterait les conflits tout en permettant à chacun de tester ses idées librement.\"\n",
    "\n",
    "Inspiré par cette idée, vous décidez d’utiliser **Hydra** pour gérer dynamiquement les configurations du pipeline. Cela permet à chaque utilisateur de définir ses propres scénarios (validation rapide, tests approfondis, etc.) sans modifier le pipeline principal. Avec **MLflow**, vous suivez chaque expérimentation et comparez les résultats, garantissant ainsi un workflow collaboratif et efficace.\n",
    "\n",
    "| **Étape/Stratégie**                   | **Validation rapide**             | **Optimisation équilibrée**             | **Validation rigoureuse**             |\n",
    "|-----------------------------------------|------------------------------------|------------------------------------|------------------------------------|\n",
    "| **Découpage des Données**             | 2 ensembles : Train/Test           | 3 ensembles : Train/Validation/Test | Validation croisée (k-folds)       |\n",
    "| **Cas d’usage**                       | Prototypage ou tests exploratoires | Comparaison rigoureuse            | Robustesse avec peu de données     |\n",
    "| **Optimisation**                       | Hyperparamètres par défaut        | Optimisation sur Validation        | Optimisation sur k-folds           |\n",
    "| **Validation**                         | Non applicable                    | Validation explicite              | Intégrée dans k-folds            |\n",
    "| **Promotion**                          | Usage limité                     | Standard en production             | Haute confiance pour production    |\n",
    "\n",
    "Ces stratégies transforment votre pipeline. Désormais, vous adaptez chaque étape à son objectif, gagnant ainsi en efficacité et en pertinence.\n",
    "\n",
    "---\n",
    "\n",
    "## Mettre en Œuvre le MLOps\n",
    "\n",
    "### Outils clés : vers une orchestration efficace\n",
    "Pour soutenir cette nouvelle approche modulaire et flexible, vous adoptez des outils spécifiques qui facilitent le suivi, l’automatisation et l’orchestration des pipelines.\n",
    "- **Tracking** : MLflow, Weights & Biases.\n",
    "- **Orchestration CI/CD** : GitHub Actions, Azure DevOps.\n",
    "- **Monitoring** : Azure Application Insights.\n",
    "\n",
    "### Étapes :\n",
    "1. **Initialiser et configurer** : Adoptez des configurations dynamiques avec Hydra ou DVC.\n",
    "2. **Expérimenter** : Logguez les paramètres et métriques pour chaque essai.\n",
    "3. **Valider et déployer** : Passez les modèles par des phases de staging avant la production.\n",
    "\n",
    "> **Exemple visuel : Logs d’Azure Application Insights affichant les dérives des données.**\n",
    "\n",
    "---\n",
    "\n",
    "## Boucle d’Amélioration Continue\n",
    "\n",
    "Le MLOps s’appuie sur une boucle d’amélioration continue, rendue possible grâce à des outils robustes et des stratégies adaptées :\n",
    "\n",
    "1. **Collecte des données réelles** : Enrichir le dataset avec des cas non couverts.\n",
    "2. **Analyse des performances** : Suivre les métriques techniques (latence, précision) et métiers (impact sur les objectifs business).\n",
    "3. **Ajustements** : Tester de nouveaux modèles, ajuster les hyperparamètres ou changer de stratégie.\n",
    "4. **Redéploiement contrôlé** : Évaluer chaque nouvelle version avant production.\n",
    "\n",
    "> **Exemple visuel : Tableau de bord montrant les métriques d’évolution d’un modèle en production.**\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Le MLOps combine **automatisation**, **traçabilité**, et **modularité** pour rendre les pipelines adaptables. En explorant plusieurs stratégies et modèles tout en intégrant un suivi actif des performances, les entreprises peuvent réduire leurs coûts tout en améliorant leurs modèles en continu.\n",
    "\n",
    "Grâce à une approche structurée, le MLOps permet d’accélérer le temps de mise sur le marché et d’augmenter la qualité des modèles, transformant ainsi l’expérimentation en avantage compétitif durable.\n",
    "\n",
    "### Outils recommandés :\n",
    "Pour mettre en œuvre ces principes de manière efficace, vous pouvez utiliser des outils tels que :\n",
    "- **DVC** : pour gérer les versions des données et des modèles.\n",
    "- **Dagster** : pour orchestrer des pipelines ML flexibles.\n",
    "- **Kubeflow** : pour automatiser et déployer à grande échelle.\n",
    "- **Airflow** : pour planifier et superviser des workflows ML complexes.\n",
    "- **MLflow** : pour le suivi des expériences et le registre de modèles.\n",
    "\n",
    "Ces outils permettent d’adopter une approche MLOps robuste et efficace, capable de s’adapter aux besoins variés des projets ML modernes.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
