{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps : Quand le Machine Learning rencontre l’esprit du DevOps\n",
    "\n",
    "Les projets de Machine Learning (ML) sont souvent comparés à des expériences scientifiques : on explore, on teste, on ajuste. Une sorte de laboratoire où chaque idée est mise à l’épreuve. Mais cette approche, bien qu’efficace pour apprendre, montre vite ses limites quand il s’agit de passer à la production.\n",
    "\n",
    "Avec des modèles plus complexes, plus de données, et des besoins de monitoring, il ne suffit plus que « ça marche dans le notebook ». C’est ici que le MLOps, inspiré du DevOps, entre en jeu : il structure, automatise et industrialise chaque étape d’un projet ML. Pour le démontrer, prenons un exemple concret avec un **projet d’analyse de sentiments**.\n",
    "-> Décrire le projet brièvement.\n",
    "\n",
    "## Étape 1 : Le point de départ – Régression logistique\n",
    "\n",
    "Le choix du modèle est une étape essentielle mais souvent complexe. Cela dépend des spécificités des données, des contraintes du projet et des objectifs visés. Une approche pragmatique consiste à commencer par un modèle simple, puis à explorer des modèles plus avancés.\n",
    "\n",
    "Dans notre projet, nous commençons par **une régression logistique**. Pourquoi ? Parce qu’elle est rapide, facile à implémenter et souvent suffisante pour valider une idée. Avec cette méthode, nous avons utilisé des caractéristiques textuelles de base, comme la fréquence des mots (bag of words). Cette **baseline** joue un double rôle : elle permet de valider rapidement la faisabilité de l'approche et sert de référence pour évaluer les améliorations apportées par des modèles plus complexes.\n",
    "\n",
    "Il nous faut donc des outils pour tracer les expériences :\n",
    "- **MLflow**: stocke les métadonnées de run et les modèles et sait pointer vers la version du dataset gérée par DVC.\n",
    "- **DVC**: stocke et versionne les datasets, sans multiplier l’espace à chaque run.\n",
    "- **git**: stocke les scripts, configurations et fichiers .dvc nécessaires pour synchroniser code et données, assurant une traçabilité complète du projet.\n",
    "\n",
    "Ensemble, ces outils créent un écosystème intégré qui garantit la reproductibilité des résultats en synchronisant chaque version du code, des données et des modèles. Ils facilitent également la collaboration entre équipes en offrant un suivi clair des expérimentations et des changements, tout en structurant des pipelines de Machine Learning robustes et facilement déployables à l'échelle.\n",
    "\n",
    "### Résultat :\n",
    "Voici les performances obtenues sur notre dataset :\n",
    "- Précision : 76,5%\n",
    "- F1-score : 74,2%\n",
    "\n",
    "\n",
    "## Étape 2 : Monter en puissance avec des modèles avancés\n",
    "\n",
    "Bien que ce soit un bon point de départ, le modèle manque de finesse pour capturer des relations contextuelles. Pour améliorer les résultats, nous avons besoin de tester des modèles plus avancés, comme des word embeddings combinés à des réseaux neuronaux (CNN ou RNN). Ces approches permettent de mieux comprendre le contexte des mots en tenant compte des séquences.\n",
    "\n",
    "Capture d’écran des résultats et du graphe des erreurs communes.\n",
    "\n",
    "Résultat avec un CNN :\n",
    "- Précision : 82,7%\n",
    "- F1-score : 81,4%\n",
    "\n",
    "Cette amélioration montre que le modèle capture désormais des nuances plus subtiles dans les sentiments. Cependant, la complexité augmente : le modèle prend plus de temps à entraîner, et le suivi des hyperparamètres devient critique.\n",
    "\n",
    "Capture d’écran des résultats comparés aux erreurs de la régression logistique.\n",
    "\n",
    "## Étape 3 : L’État de l’art avec BERT\n",
    "\n",
    "Enfin, nous avons utilisé BERT, un modèle préentraîné d’État de l’art, capable de comprendre les subtilités linguistiques et les relations complexes dans les phrases. Avec BERT, les résultats ont été impressionnants :\n",
    "\n",
    "Résultat avec BERT :\n",
    "- Précision : 89,5%\n",
    "- F1-score : 88,9%\n",
    "\n",
    "Cependant, l’utilisation de BERT a introduit de nouveaux défis :\n",
    "- Temps d’entraînement prolongé : Il a fallu 10 fois plus de temps que pour la régression logistique.\n",
    "- Infrastructure nécessaire : L’entraînement a nécessité un GPU, et le suivi des versions de données et de modèles est devenu encore plus crucial.\n",
    "\n",
    "Capture d’écran des résultats, avec une visualisation des prédictions BERT sur des exemples complexes.\n",
    "\n",
    "## Passage en production avec MLOps\n",
    "\n",
    "À chaque étape, les modèles deviennent plus performants, mais aussi plus complexes à gérer. C’est ici que le MLOps prend tout son sens. Voici comment il a structuré notre projet :\n",
    "\n",
    "### 1. Suivi des expérimentations\n",
    "\n",
    "Grâce à des outils comme MLflow, nous avons enregistré chaque expérimentation :\n",
    "- Version des données utilisées.\n",
    "- Hyperparamètres et configurations des modèles.\n",
    "- Performances obtenues (précision, F1-score, etc.).\n",
    "\n",
    "Cela nous a permis de comparer les résultats facilement et de justifier nos choix à chaque étape.\n",
    "\n",
    "### 2. Automatisation des pipelines\n",
    "\n",
    "Nous avons automatisé les étapes clés :\n",
    "- Préparation des données (nettoyage, transformation).\n",
    "- Entraînement des modèles avec différentes configurations.\n",
    "- Validation sur des ensembles indépendants.\n",
    "\n",
    "Un outil comme Kubeflow nous a aidés à orchestrer ces tâches et à les rendre reproductibles.\n",
    "\n",
    "### 3. Monitoring en production\n",
    "\n",
    "Une fois BERT déployé, un système de monitoring a été mis en place pour surveiller les performances en temps réel. Par exemple :\n",
    "- Détection des drifts de données : Si les avis clients évoluent (argot, emojis, etc.).\n",
    "- Suivi des métriques : Si le modèle perd en précision ou en rappel.\n",
    "\n",
    "Conclusion : Apprendre, structurer, et industrialiser\n",
    "\n",
    "L’histoire de ce projet d’analyse de sentiments montre bien la double nature des projets ML. D’un côté, il y a l’aspect exploratoire : tester différents modèles et approches pour trouver ce qui fonctionne. De l’autre, il y a le besoin d’industrialisation, où la reproductibilité et la fiabilité deviennent essentielles.\n",
    "\n",
    "Le MLOps, en s’appuyant sur les principes du DevOps, nous a permis de structurer cette transition. Il a transformé une série d’expérimentations en une solution robuste, prête pour la production. Et à chaque étape, il nous a offert des outils pour gérer la complexité croissante du Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
