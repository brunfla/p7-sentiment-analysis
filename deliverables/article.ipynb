{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps : Quand le Machine Learning rencontre l’esprit du DevOps\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Les projets de Machine Learning (ML) sont souvent comparés à des expériences scientifiques : on explore, on teste, on ajuste. Une sorte de laboratoire où chaque idée est mise à l’épreuve. Mais cette approche, bien qu’efficace pour apprendre, montre vite ses limites quand il s’agit de passer à la production.\n",
    "\n",
    "Avec des modèles plus complexes, plus de données, et des besoins de monitoring, il ne suffit plus que « ça marche dans le notebook ». C’est ici que le MLOps, inspiré du DevOps, entre en jeu : il structure, automatise et industrialise chaque étape d’un projet ML. Pour le démontrer, prenons un exemple concret avec un **projet d’analyse de sentiments**. Il s'agit de créer un prototype d'IA pour prédire le sentiment des tweets à partir de données open source et déployé le model via une API Cloud.\n",
    "\n",
    "## 1) Premier pas\n",
    "\n",
    "L'une des premières étapes est le choix du modèle, c'est une étape essentielle mais souvent complexe. Cela dépend des spécificités des données, des contraintes du projet et des objectifs visés. Une approche pragmatique consiste à commencer par un modèle simple, puis à explorer des modèles de plus en plus avancés.\n",
    "\n",
    "Pour notre projet d'analyse de sentiment, nous commençons par **une régression logistique**. Pourquoi ? Parce qu’elle est rapide, facile à implémenter et souvent suffisante pour valider une idée. Avec cette méthode, nous avons utilisé des caractéristiques textuelles de base, comme la fréquence des mots (bag of words). Cette **baseline** joue un double rôle : elle permet de valider rapidement la faisabilité de l'approche et sert de référence pour évaluer les améliorations apportées par des modèles plus complexes.\n",
    "\n",
    "Une fois que notre régression logistique est en place et que nous avons une baseline, il devient crucial de structurer notre approche pour garantir la reproductibilité des résultats, faciliter la comparaison des expérimentations, et préparer le modèle au déploiement en production, ce que permettent les principes du MLOps et des outils comme **MLflow**. **MLflow** stocke les métadonnées de run et les modèles, tout en assurant le suivi des expérimentations.\n",
    "\n",
    "\n",
    "\n",
    "En ce qui concerne MLops, nous allons utiliser conjointement plusieurs outils :\n",
    "- **MLflow**: stocke les métadonnées de run et les modèles.\n",
    "- **DVC**: stocke et versionne les datasets, sans multiplier l’espace à chaque run. DVC est conçu pour gérer efficacement les changements et éviter de télécharger ou de pousser inutilement des données si elles n'ont pas été modifiées.\n",
    "- **Git**: stocke les scripts, configurations et fichiers .dvc nécessaires pour synchroniser code et données, assurant une traçabilité complète du projet.\n",
    "- **Docker/Conda**: Garantie d'avoir un environnement reproductible. \n",
    "    - ex : conda pack -n mlops-env -o mlops-env.tar.gz && docker build -f Dockerfile.mlops-env -t mlops-env:v1 .\n",
    "\n",
    "Ensemble, ces outils créent un écosystème intégré qui garantit la reproductibilité des résultats en synchronisant chaque version du code, des données et des modèles. Ils facilitent également la collaboration entre équipes en offrant un suivi clair des expérimentations et des changements, tout en structurant des pipelines de Machine Learning robustes et facilement déployables à l'échelle.\n",
    "\n",
    "\n",
    "\n",
    "### Points clés :\n",
    "- Utilisation de Docker\n",
    "- L'utilisation de DVC et git permet de faire en sorte que le script \n",
    "- l'utilisation d'Hydra permet de changer de passer d'une expérience à autre simplement.\n",
    "\n",
    "### Résultats :\n",
    "Voici les performances obtenues sur notre dataset :\n",
    "- Précision : 76,5%\n",
    "- F1-score : 74,2%\n",
    "\n",
    "## Création du pipeline avec DVC (Data Version Control)\n",
    "\n",
    "Dans un pipeline DevOps classique, vous codez, vous poussez sur Git, et boum, tout se construit et se déploie automatiquement. En MLOps, on va un cran plus loin, les étapes classiques sont : \n",
    "- Préparer les données (nettoyage, enrichissement).\n",
    "- Entraîner les modèles (et tester plusieurs configurations).\n",
    "- Valider les résultats (cross-validation, ensembles de test).\n",
    "- Et ensuite ? Surveiller en continu. Parce qu’un modèle, contrairement à du code, peut se dégrader avec le temps !(drift)\n",
    "\n",
    "En machine learning, les pipelines impliquent non seulement du code, mais aussi des données, des modèles, et des étapes de transformation interconnectées. C'est là que DVC devient un outil indispensable. Inspiré de Git, DVC détecte automatiquement les changements dans votre pipeline, ne réexécutant que les étapes nécessaires pour garantir une gestion efficace et reproductible des workflows ML.\n",
    "\n",
    "\n",
    "## Monter en puissance avec des modèles avancés\n",
    "\n",
    "Bien que ce soit un bon point de départ, le modèle manque de finesse pour capturer des relations contextuelles. Pour améliorer les résultats, nous avons besoin de tester des modèles plus avancés, comme des word embeddings combinés à des réseaux neuronaux (CNN ou RNN). Ces approches permettent de mieux comprendre le contexte des mots en tenant compte des séquences.\n",
    "\n",
    "Avec Hydra, il devient facile d'ajouter des configurations sans trop toucher aux scripts python.\n",
    "\n",
    "Capture d’écran des résultats et du graphe des erreurs communes.\n",
    "\n",
    "Résultat avec un CNN :\n",
    "- Précision : 82,7%\n",
    "- F1-score : 81,4%\n",
    "\n",
    "Cette amélioration montre que le modèle capture désormais des nuances plus subtiles dans les sentiments. Cependant, la complexité augmente : le modèle prend plus de temps à entraîner, et le suivi des hyperparamètres devient critique.\n",
    "\n",
    "Capture d’écran des résultats comparés aux erreurs de la régression logistique.\n",
    "\n",
    "## Étape 3 : L’État de l’art avec BERT\n",
    "\n",
    "Enfin, nous avons utilisé BERT, un modèle préentraîné d’État de l’art, capable de comprendre les subtilités linguistiques et les relations complexes dans les phrases. Avec BERT, les résultats ont été impressionnants :\n",
    "\n",
    "Résultat avec BERT :\n",
    "- Précision : 89,5%\n",
    "- F1-score : 88,9%\n",
    "\n",
    "Cependant, l’utilisation de BERT a introduit de nouveaux défis :\n",
    "- Temps d’entraînement prolongé : Il a fallu 10 fois plus de temps que pour la régression logistique.\n",
    "- Infrastructure nécessaire : L’entraînement a nécessité un GPU, et le suivi des versions de données et de modèles est devenu encore plus crucial.\n",
    "\n",
    "Capture d’écran des résultats, avec une visualisation des prédictions BERT sur des exemples complexes.\n",
    "\n",
    "## Passage en production avec MLOps\n",
    "\n",
    "À chaque étape, les modèles deviennent plus performants, mais aussi plus complexes à gérer. C’est ici que le MLOps prend tout son sens. Voici comment il a structuré notre projet :\n",
    "\n",
    "### 1. Suivi des expérimentations\n",
    "\n",
    "Grâce à des outils comme MLflow, nous avons enregistré chaque expérimentation :\n",
    "- Version des données utilisées.\n",
    "- Hyperparamètres et configurations des modèles.\n",
    "- Performances obtenues (précision, F1-score, etc.).\n",
    "\n",
    "Cela nous a permis de comparer les résultats facilement et de justifier nos choix à chaque étape.\n",
    "\n",
    "### 2. Automatisation des pipelines\n",
    "\n",
    "Nous avons automatisé les étapes clés :\n",
    "- Préparation des données (nettoyage, transformation).\n",
    "- Entraînement des modèles avec différentes configurations.\n",
    "- Validation sur des ensembles indépendants.\n",
    "\n",
    "Un outil comme Kubeflow nous a aidés à orchestrer ces tâches et à les rendre reproductibles.\n",
    "\n",
    "### 3. Monitoring en production\n",
    "\n",
    "Une fois BERT déployé, un système de monitoring a été mis en place pour surveiller les performances en temps réel. Par exemple :\n",
    "- Détection des drifts de données : Si les avis clients évoluent (argot, emojis, etc.).\n",
    "- Suivi des métriques : Si le modèle perd en précision ou en rappel.\n",
    "\n",
    "Conclusion : Apprendre, structurer, et industrialiser\n",
    "\n",
    "L’histoire de ce projet d’analyse de sentiments montre bien la double nature des projets ML. D’un côté, il y a l’aspect exploratoire : tester différents modèles et approches pour trouver ce qui fonctionne. De l’autre, il y a le besoin d’industrialisation, où la reproductibilité et la fiabilité deviennent essentielles.\n",
    "\n",
    "Le MLOps, en s’appuyant sur les principes du DevOps, nous a permis de structurer cette transition. Il a transformé une série d’expérimentations en une solution robuste, prête pour la production. Et à chaque étape, il nous a offert des outils pour gérer la complexité croissante du Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
