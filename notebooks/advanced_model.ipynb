{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réalisez une analyse de sentiments grâce au Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## advanced-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>a thats a bummer you shoulda got david carr of...</td>\n",
       "      <td>['thats', 'bummer', 'shoulda', 'got', 'david',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>['upset', 'cant', 'update', 'facebook', 'texti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>['dived', 'many', 'times', 'ball', 'managed', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>['whole', 'body', 'feels', 'itchy', 'like', 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>no its not behaving at all im mad why am i her...</td>\n",
       "      <td>['behaving', 'im', 'mad', 'cant', 'see']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   timestamp                          date     query             user  \\\n",
       "0   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1   0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2   0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3   0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4   0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  a thats a bummer you shoulda got david carr of...   \n",
       "1  is upset that he cant update his facebook by t...   \n",
       "2  i dived many times for the ball managed to sav...   \n",
       "3     my whole body feels itchy and like its on fire   \n",
       "4  no its not behaving at all im mad why am i her...   \n",
       "\n",
       "                                     tweet_tokenized  \n",
       "0  ['thats', 'bummer', 'shoulda', 'got', 'david',...  \n",
       "1  ['upset', 'cant', 'update', 'facebook', 'texti...  \n",
       "2  ['dived', 'many', 'times', 'ball', 'managed', ...  \n",
       "3  ['whole', 'body', 'feels', 'itchy', 'like', 'f...  \n",
       "4           ['behaving', 'im', 'mad', 'cant', 'see']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Chargement du fichier avec un encodage différent\n",
    "df = pd.read_csv(\"./output/data_clean.csv\")\n",
    "\n",
    "# Vérification des premières lignes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"tweet\"].isna() | (df[\"tweet\"] == \"\")]\n",
    "df = df[~(df['tweet'].isna() | (df['tweet'] == \"\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prétraitement et Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # WordNet dépend de cette ressource\n",
    "nltk.download('punkt')    # Pour la tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stemming et Lemmatization\n",
    "\n",
    "- **stemming** : Le stemming consiste à troncater un mot jusqu’à sa racine ou un radical commun en appliquant des règles heuristiques simples. Cette approche est souvent rapide, mais elle peut produire des formes de mots non valides.\n",
    "- **Lemmatization** : La lemmatisation consiste à réduire un mot à sa \"lemme\", c’est-à-dire sa forme canonique ou de base, en tenant compte de son contexte linguistique et de sa catégorie grammaticale.\n",
    "    - ex :\n",
    "        -  Happily\t-> Happy\n",
    "        -  Better\t-> Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import numpy as np\n",
    "\n",
    "# Choix des techniques de prétraitement\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text, technique=\"lemmatization\"):\n",
    "    if technique == \"lemmatization\":\n",
    "        return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    elif technique == \"stemming\":\n",
    "        return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "df['processed_tweet_lemma'] = df['tweet'].apply(lambda x: preprocess_text(x, \"lemmatization\"))\n",
    "df['processed_tweet_stem'] = df['tweet'].apply(lambda x: preprocess_text(x, \"stemming\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection et Découpage des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['processed_tweet_lemma']  # Peut être changé pour `processed_tweet_stem`\n",
    "y = df['id'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding avec GloVe (Global Vectors for Word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe (Global Vectors for Word Representation) est une méthode populaire pour générer des embeddings pré-entraînés. Développé par Stanford, GloVe repose sur l’idée de capturer les relations sémantiques et contextuelles entre les mots en utilisant les **cooccurrences globales** dans un corpus de texte.\n",
    "\n",
    "- **cooccurrences globales** :  Les cooccurrences globales utilisées dans des méthodes comme GloVe sont obtenues en agrégeant les cooccurrences locales sur l'ensemble du corpus. Cela signifie que les cooccurrences locales (les mots qui apparaissent ensemble dans une fenêtre contextuelle autour d'un mot cible) sont comptabilisées et accumulées pour former une vue d'ensemble du corpus. \n",
    "\n",
    "- **descente de gradient** : La descente de gradient est une méthode d'optimisation utilisée pour minimiser une fonction objective (ou fonction de coût) dans de nombreux algorithmes de machine learning, y compris les réseaux neuronaux. C'est un processus itératif qui ajuste les paramètres du modèle (comme les poids et les biais) pour réduire l'erreur entre les prédictions du modèle et les valeurs réelles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- glove.6B.50d.txt  : 50 dimensions\n",
    "- glove.6B.100d.txt : 100 dimensions\n",
    "- glove.6B.200d.txt : 200 dimensions\n",
    "- glove.6B.300d.txt : 300 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embedding_index = {}\n",
    "\n",
    "with open(\"./input/glove.6B.300d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coeffs\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "max_length = 300\n",
    "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prépare MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/277281536415448661', creation_time=1733133411530, experiment_id='277281536415448661', last_update_time=1733133411530, lifecycle_stage='active', name='p7-sentiment-analysis', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définir l'URI de tracking pour MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Vérifier et terminer les runs actives\n",
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Définir un nom d'expérience\n",
    "experiment_name = \"p7-sentiment-analysis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle LSTM Bidirectionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1733408458.840353  126573 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5520 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733408463.436164  151012 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31932/31932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2514s\u001b[0m 79ms/step - accuracy: 0.7806 - loss: 0.4593 - val_accuracy: 0.8161 - val_loss: 0.4034\n",
      "Epoch 2/5\n",
      "\u001b[1m31932/31932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2359s\u001b[0m 74ms/step - accuracy: 0.8258 - loss: 0.3865 - val_accuracy: 0.8233 - val_loss: 0.3896\n",
      "Epoch 3/5\n",
      "\u001b[1m31932/31932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2342s\u001b[0m 73ms/step - accuracy: 0.8365 - loss: 0.3659 - val_accuracy: 0.8250 - val_loss: 0.3877\n",
      "Epoch 4/5\n",
      "\u001b[1m31932/31932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2406s\u001b[0m 75ms/step - accuracy: 0.8444 - loss: 0.3518 - val_accuracy: 0.8241 - val_loss: 0.3891\n",
      "Epoch 5/5\n",
      "\u001b[1m31932/31932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2492s\u001b[0m 78ms/step - accuracy: 0.8486 - loss: 0.3442 - val_accuracy: 0.8219 - val_loss: 0.3954\n",
      "\u001b[1m9979/9979\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/05 18:48:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/12/05 18:49:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run bidirectional_lstm at: http://127.0.0.1:5000/#/experiments/277281536415448661/runs/605b207f04ec4418bc4bc8cff95827e7\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/277281536415448661\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'true' has type str, but expected one of: int, float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, f1_lstm)\n\u001b[1;32m     22\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlog_model(model_lstm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlemmatization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglove_embedding_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding_dim)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Ajouter le modèle au Model Registry\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/mlflow/tracking/fluent.py:916\u001b[0m, in \u001b[0;36mlog_metric\u001b[0;34m(key, value, step, synchronous, timestamp, run_id)\u001b[0m\n\u001b[1;32m    914\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m    915\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/mlflow/tracking/client.py:1525\u001b[0m, in \u001b[0;36mMlflowClient.log_metric\u001b[0;34m(self, run_id, key, value, timestamp, step, synchronous)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;124;03mLog a metric against the run ID.\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;124;03m    status: FINISHED\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1523\u001b[0m     synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m   1524\u001b[0m )\n\u001b[0;32m-> 1525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:583\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_metric\u001b[0;34m(self, run_id, key, value, timestamp, step, synchronous)\u001b[0m\n\u001b[1;32m    581\u001b[0m metric \u001b[38;5;241m=\u001b[39m Metric(key, metric_value, timestamp, step)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mlog_metric_async(run_id, metric)\n",
      "File \u001b[0;32m~/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:398\u001b[0m, in \u001b[0;36mRestStore.log_metric\u001b[0;34m(self, run_id, metric)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_metric\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, metric):\n\u001b[1;32m    390\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    Log a metric for the specified run\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m        metric: Metric instance to log\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[0;32m--> 398\u001b[0m         \u001b[43mLogMetric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_uuid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     )\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_endpoint(LogMetric, req_body)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'true' has type str, but expected one of: int, float"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "with mlflow.start_run(run_name=\"bidirectional_lstm\") as run:\n",
    "    model_lstm = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False),\n",
    "        Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        Dropout(0.5),\n",
    "        Bidirectional(LSTM(64)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model_lstm.fit(X_train_pad, y_train, validation_split=0.2, epochs=5, batch_size=32)\n",
    "\n",
    "    # Évaluation\n",
    "    y_pred_lstm = (model_lstm.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "    acc_lstm = accuracy_score(y_test, y_pred_lstm)\n",
    "    f1_lstm = f1_score(y_test, y_pred_lstm)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc_lstm)\n",
    "    mlflow.log_metric(\"f1_score\", f1_lstm)\n",
    "    mlflow.keras.log_model(model_lstm, \"lstm_model\")\n",
    "    \n",
    "\n",
    "    mlflow.log_metric(\"lemmatization\", \"true\")\n",
    "    mlflow.log_metric(\"glove_embedding_dim\", embedding_dim)\n",
    "\n",
    "    # Ajouter le modèle au Model Registry\n",
    "    model_name = \"bidirectional-lstm\"\n",
    "    client = MlflowClient()\n",
    "    model_uri = f\"runs:/{run.info.run_id}/lstm_model\"\n",
    "    try:\n",
    "        client.get_registered_model(model_name)\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        client.create_registered_model(model_name)\n",
    "    client.create_model_version(name=model_name, source=model_uri, run_id=run.info.run_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/02 23:26:50 INFO mlflow.tracking.fluent: Experiment with name 'bert-classification-experiment' does not exist. Creating a new experiment.\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "63863/63863 [==============================] - 10863s 170ms/step - loss: 0.6929 - accuracy: 0.5001 - val_loss: 0.6933 - val_accuracy: 0.5002\n",
      "Epoch 2/3\n",
      "63863/63863 [==============================] - 10840s 170ms/step - loss: 0.6928 - accuracy: 0.4991 - val_loss: 0.6933 - val_accuracy: 0.4998\n",
      "Epoch 3/3\n",
      "63863/63863 [==============================] - 10873s 170ms/step - loss: 0.6928 - accuracy: 0.4996 - val_loss: 0.6933 - val_accuracy: 0.4998\n",
      "9979/9979 [==============================] - 962s 96ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/03 08:49:17 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "/home/bruno/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n",
      "2024/12/03 08:49:31 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpg7vglg8h/model, flavor: keras). Fall back to return ['keras==3.6.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/12/03 08:49:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/12/03 08:49:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: bert-classification, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5013262848678256\n",
      "Test F1 Score: 0.667844545080967\n",
      "🏃 View run bert_classification at: http://127.0.0.1:5000/#/experiments/740765759709431351/runs/5752810efd5a440e9e99c9508e6ecfc1\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/740765759709431351\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer, AdamWeightDecay\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Configurations de MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Vérifier et terminer les runs actives\n",
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Définir un nom d'expérience\n",
    "experiment_name = \"bert-classification-experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Démarrer une run MLflow\n",
    "with mlflow.start_run(run_name=\"bert_classification\") as run:\n",
    "    # Initialisation du tokenizer BERT\n",
    "    tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Tokenisation des données d'entraînement et de test\n",
    "    max_length = 100\n",
    "    X_train_enc = tokenizer_bert(list(X_train), truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "    X_test_enc = tokenizer_bert(list(X_test), truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "\n",
    "    # Initialisation du modèle BERT pour la classification\n",
    "    model_bert = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "    # Configuration de l'optimiseur AdamWeightDecay\n",
    "    optimizer = AdamWeightDecay(learning_rate=5e-5, weight_decay_rate=0.01)\n",
    "\n",
    "    # Compilation du modèle\n",
    "    model_bert.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    model_bert.fit(\n",
    "        X_train_enc['input_ids'], \n",
    "        y_train, \n",
    "        validation_split=0.2, \n",
    "        epochs=3, \n",
    "        batch_size=16\n",
    "    )\n",
    "\n",
    "    # Évaluation sur le jeu de test\n",
    "    y_pred_bert = np.argmax(model_bert.predict(X_test_enc['input_ids']).logits, axis=1)\n",
    "    acc_bert = accuracy_score(y_test, y_pred_bert)\n",
    "    f1_bert = f1_score(y_test, y_pred_bert)\n",
    "\n",
    "    # Enregistrer les métriques dans MLflow\n",
    "    mlflow.log_metric(\"accuracy\", acc_bert)\n",
    "    mlflow.log_metric(\"f1_score\", f1_bert)\n",
    "\n",
    "    # Enregistrer le modèle dans MLflow\n",
    "    mlflow.keras.log_model(model_bert, \"bert_model\")\n",
    "\n",
    "    # Ajouter le modèle au Model Registry\n",
    "    model_name = \"bert-classification\"\n",
    "    client = MlflowClient()\n",
    "    model_uri = f\"runs:/{run.info.run_id}/bert_model\"\n",
    "\n",
    "    try:\n",
    "        client.get_registered_model(model_name)\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        client.create_registered_model(model_name)\n",
    "\n",
    "    client.create_model_version(name=model_name, source=model_uri, run_id=run.info.run_id)\n",
    "\n",
    "    # Affichage des résultats finaux\n",
    "    print(\"Test Accuracy:\", acc_bert)\n",
    "    print(\"Test F1 Score:\", f1_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats Finaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LSTM Accuracy:\", acc_lstm, \"F1 Score:\", f1_lstm)\n",
    "print(\"BERT Accuracy:\", acc_bert, \"F1 Score:\", f1_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorisation parie en production.\n",
    "TEster USE et Word Embeding :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
