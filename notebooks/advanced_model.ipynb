{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R√©alisez une analyse de sentiments gr√¢ce au Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## advanced-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>a thats a bummer you shoulda got david carr of...</td>\n",
       "      <td>['thats', 'bummer', 'shoulda', 'got', 'david',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>['upset', 'cant', 'update', 'facebook', 'texti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>['dived', 'many', 'times', 'ball', 'managed', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>['whole', 'body', 'feels', 'itchy', 'like', 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>no its not behaving at all im mad why am i her...</td>\n",
       "      <td>['behaving', 'im', 'mad', 'cant', 'see']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   timestamp                          date     query             user  \\\n",
       "0   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1   0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2   0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3   0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4   0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  a thats a bummer you shoulda got david carr of...   \n",
       "1  is upset that he cant update his facebook by t...   \n",
       "2  i dived many times for the ball managed to sav...   \n",
       "3     my whole body feels itchy and like its on fire   \n",
       "4  no its not behaving at all im mad why am i her...   \n",
       "\n",
       "                                     tweet_tokenized  \n",
       "0  ['thats', 'bummer', 'shoulda', 'got', 'david',...  \n",
       "1  ['upset', 'cant', 'update', 'facebook', 'texti...  \n",
       "2  ['dived', 'many', 'times', 'ball', 'managed', ...  \n",
       "3  ['whole', 'body', 'feels', 'itchy', 'like', 'f...  \n",
       "4           ['behaving', 'im', 'mad', 'cant', 'see']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Chargement du fichier avec un encodage diff√©rent\n",
    "df = pd.read_csv(\"./output/data_clean.csv\")\n",
    "\n",
    "# V√©rification des premi√®res lignes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"tweet\"].isna() | (df[\"tweet\"] == \"\")]\n",
    "df = df[~(df['tweet'].isna() | (df['tweet'] == \"\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pr√©traitement et Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # WordNet d√©pend de cette ressource\n",
    "nltk.download('punkt')    # Pour la tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stemming et Lemmatization\n",
    "\n",
    "- **stemming** : Le stemming consiste √† troncater un mot jusqu‚Äô√† sa racine ou un radical commun en appliquant des r√®gles heuristiques simples. Cette approche est souvent rapide, mais elle peut produire des formes de mots non valides.\n",
    "- **Lemmatization** : La lemmatisation consiste √† r√©duire un mot √† sa \"lemme\", c‚Äôest-√†-dire sa forme canonique ou de base, en tenant compte de son contexte linguistique et de sa cat√©gorie grammaticale.\n",
    "    - ex :\n",
    "        -  Happily\t-> Happy\n",
    "        -  Better\t-> Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import numpy as np\n",
    "\n",
    "# Choix des techniques de pr√©traitement\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text, technique=\"lemmatization\"):\n",
    "    if technique == \"lemmatization\":\n",
    "        return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    elif technique == \"stemming\":\n",
    "        return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "df['processed_tweet_lemma'] = df['tweet'].apply(lambda x: preprocess_text(x, \"lemmatization\"))\n",
    "df['processed_tweet_stem'] = df['tweet'].apply(lambda x: preprocess_text(x, \"stemming\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S√©lection et D√©coupage des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['processed_tweet_lemma']  # Peut √™tre chang√© pour `processed_tweet_stem`\n",
    "y = df['id'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding avec GloVe (Global Vectors for Word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe (Global Vectors for Word Representation) est une m√©thode populaire pour g√©n√©rer des embeddings pr√©-entra√Æn√©s. D√©velopp√© par Stanford, GloVe repose sur l‚Äôid√©e de capturer les relations s√©mantiques et contextuelles entre les mots en utilisant les **cooccurrences globales** dans un corpus de texte.\n",
    "\n",
    "- **cooccurrences globales** :  Les cooccurrences globales utilis√©es dans des m√©thodes comme GloVe sont obtenues en agr√©geant les cooccurrences locales sur l'ensemble du corpus. Cela signifie que les cooccurrences locales (les mots qui apparaissent ensemble dans une fen√™tre contextuelle autour d'un mot cible) sont comptabilis√©es et accumul√©es pour former une vue d'ensemble du corpus. \n",
    "\n",
    "- **descente de gradient** : La descente de gradient est une m√©thode d'optimisation utilis√©e pour minimiser une fonction objective (ou fonction de co√ªt) dans de nombreux algorithmes de machine learning, y compris les r√©seaux neuronaux. C'est un processus it√©ratif qui ajuste les param√®tres du mod√®le (comme les poids et les biais) pour r√©duire l'erreur entre les pr√©dictions du mod√®le et les valeurs r√©elles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- glove.6B.50d.txt  : 50 dimensions\n",
    "- glove.6B.100d.txt : 100 dimensions\n",
    "- glove.6B.200d.txt : 200 dimensions\n",
    "- glove.6B.300d.txt : 300 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embedding_index = {}\n",
    "\n",
    "with open(\"./input/glove.6B.300d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coeffs\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "max_length = 300\n",
    "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pr√©pare MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/277281536415448661', creation_time=1733133411530, experiment_id='277281536415448661', last_update_time=1733133411530, lifecycle_stage='active', name='p7-sentiment-analysis', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D√©finir l'URI de tracking pour MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# V√©rifier et terminer les runs actives\n",
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n",
    "\n",
    "# D√©finir un nom d'exp√©rience\n",
    "experiment_name = \"p7-sentiment-analysis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mod√®le LSTM Bidirectionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1733408458.840353  126573 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5520 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733408463.436164  151012 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31932/31932\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2514s\u001b[0m 79ms/step - accuracy: 0.7806 - loss: 0.4593 - val_accuracy: 0.8161 - val_loss: 0.4034\n",
      "Epoch 2/5\n",
      "\u001b[1m31932/31932\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2359s\u001b[0m 74ms/step - accuracy: 0.8258 - loss: 0.3865 - val_accuracy: 0.8233 - val_loss: 0.3896\n",
      "Epoch 3/5\n",
      "\u001b[1m31932/31932\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2342s\u001b[0m 73ms/step - accuracy: 0.8365 - loss: 0.3659 - val_accuracy: 0.8250 - val_loss: 0.3877\n",
      "Epoch 4/5\n",
      "\u001b[1m31932/31932\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2406s\u001b[0m 75ms/step - accuracy: 0.8444 - loss: 0.3518 - val_accuracy: 0.8241 - val_loss: 0.3891\n",
      "Epoch 5/5\n",
      "\u001b[1m31932/31932\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2492s\u001b[0m 78ms/step - accuracy: 0.8486 - loss: 0.3442 - val_accuracy: 0.8219 - val_loss: 0.3954\n",
      "\u001b[1m9979/9979\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/05 18:48:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/12/05 18:49:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bidirectional_lstm at: http://127.0.0.1:5000/#/experiments/277281536415448661/runs/605b207f04ec4418bc4bc8cff95827e7\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/277281536415448661\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'true' has type str, but expected one of: int, float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, f1_lstm)\n\u001b[1;32m     22\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlog_model(model_lstm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlemmatization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglove_embedding_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding_dim)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Ajouter le mod√®le au Model Registry\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/mlflow/tracking/fluent.py:916\u001b[0m, in \u001b[0;36mlog_metric\u001b[0;34m(key, value, step, synchronous, timestamp, run_id)\u001b[0m\n\u001b[1;32m    914\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m    915\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/mlflow/tracking/client.py:1525\u001b[0m, in \u001b[0;36mMlflowClient.log_metric\u001b[0;34m(self, run_id, key, value, timestamp, step, synchronous)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;124;03mLog a metric against the run ID.\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;124;03m    status: FINISHED\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1523\u001b[0m     synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m   1524\u001b[0m )\n\u001b[0;32m-> 1525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:583\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_metric\u001b[0;34m(self, run_id, key, value, timestamp, step, synchronous)\u001b[0m\n\u001b[1;32m    581\u001b[0m metric \u001b[38;5;241m=\u001b[39m Metric(key, metric_value, timestamp, step)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mlog_metric_async(run_id, metric)\n",
      "File \u001b[0;32m~/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:398\u001b[0m, in \u001b[0;36mRestStore.log_metric\u001b[0;34m(self, run_id, metric)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_metric\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, metric):\n\u001b[1;32m    390\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    Log a metric for the specified run\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m        metric: Metric instance to log\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[0;32m--> 398\u001b[0m         \u001b[43mLogMetric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_uuid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     )\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_endpoint(LogMetric, req_body)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'true' has type str, but expected one of: int, float"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "with mlflow.start_run(run_name=\"bidirectional_lstm\") as run:\n",
    "    model_lstm = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False),\n",
    "        Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        Dropout(0.5),\n",
    "        Bidirectional(LSTM(64)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model_lstm.fit(X_train_pad, y_train, validation_split=0.2, epochs=5, batch_size=32)\n",
    "\n",
    "    # √âvaluation\n",
    "    y_pred_lstm = (model_lstm.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "    acc_lstm = accuracy_score(y_test, y_pred_lstm)\n",
    "    f1_lstm = f1_score(y_test, y_pred_lstm)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc_lstm)\n",
    "    mlflow.log_metric(\"f1_score\", f1_lstm)\n",
    "    mlflow.keras.log_model(model_lstm, \"lstm_model\")\n",
    "    \n",
    "\n",
    "    mlflow.log_metric(\"lemmatization\", \"true\")\n",
    "    mlflow.log_metric(\"glove_embedding_dim\", embedding_dim)\n",
    "\n",
    "    # Ajouter le mod√®le au Model Registry\n",
    "    model_name = \"bidirectional-lstm\"\n",
    "    client = MlflowClient()\n",
    "    model_uri = f\"runs:/{run.info.run_id}/lstm_model\"\n",
    "    try:\n",
    "        client.get_registered_model(model_name)\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        client.create_registered_model(model_name)\n",
    "    client.create_model_version(name=model_name, source=model_uri, run_id=run.info.run_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mod√®le BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/02 23:26:50 INFO mlflow.tracking.fluent: Experiment with name 'bert-classification-experiment' does not exist. Creating a new experiment.\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "63863/63863 [==============================] - 10863s 170ms/step - loss: 0.6929 - accuracy: 0.5001 - val_loss: 0.6933 - val_accuracy: 0.5002\n",
      "Epoch 2/3\n",
      "63863/63863 [==============================] - 10840s 170ms/step - loss: 0.6928 - accuracy: 0.4991 - val_loss: 0.6933 - val_accuracy: 0.4998\n",
      "Epoch 3/3\n",
      "63863/63863 [==============================] - 10873s 170ms/step - loss: 0.6928 - accuracy: 0.4996 - val_loss: 0.6933 - val_accuracy: 0.4998\n",
      "9979/9979 [==============================] - 962s 96ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/03 08:49:17 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "/home/bruno/miniconda3/envs/p6-wsl/lib/python3.9/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n",
      "2024/12/03 08:49:31 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpg7vglg8h/model, flavor: keras). Fall back to return ['keras==3.6.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/12/03 08:49:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/12/03 08:49:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: bert-classification, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5013262848678256\n",
      "Test F1 Score: 0.667844545080967\n",
      "üèÉ View run bert_classification at: http://127.0.0.1:5000/#/experiments/740765759709431351/runs/5752810efd5a440e9e99c9508e6ecfc1\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/740765759709431351\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer, AdamWeightDecay\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Configurations de MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# V√©rifier et terminer les runs actives\n",
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n",
    "\n",
    "# D√©finir un nom d'exp√©rience\n",
    "experiment_name = \"bert-classification-experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# D√©marrer une run MLflow\n",
    "with mlflow.start_run(run_name=\"bert_classification\") as run:\n",
    "    # Initialisation du tokenizer BERT\n",
    "    tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Tokenisation des donn√©es d'entra√Ænement et de test\n",
    "    max_length = 100\n",
    "    X_train_enc = tokenizer_bert(list(X_train), truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "    X_test_enc = tokenizer_bert(list(X_test), truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "\n",
    "    # Initialisation du mod√®le BERT pour la classification\n",
    "    model_bert = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "    # Configuration de l'optimiseur AdamWeightDecay\n",
    "    optimizer = AdamWeightDecay(learning_rate=5e-5, weight_decay_rate=0.01)\n",
    "\n",
    "    # Compilation du mod√®le\n",
    "    model_bert.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entra√Ænement du mod√®le\n",
    "    model_bert.fit(\n",
    "        X_train_enc['input_ids'], \n",
    "        y_train, \n",
    "        validation_split=0.2, \n",
    "        epochs=3, \n",
    "        batch_size=16\n",
    "    )\n",
    "\n",
    "    # √âvaluation sur le jeu de test\n",
    "    y_pred_bert = np.argmax(model_bert.predict(X_test_enc['input_ids']).logits, axis=1)\n",
    "    acc_bert = accuracy_score(y_test, y_pred_bert)\n",
    "    f1_bert = f1_score(y_test, y_pred_bert)\n",
    "\n",
    "    # Enregistrer les m√©triques dans MLflow\n",
    "    mlflow.log_metric(\"accuracy\", acc_bert)\n",
    "    mlflow.log_metric(\"f1_score\", f1_bert)\n",
    "\n",
    "    # Enregistrer le mod√®le dans MLflow\n",
    "    mlflow.keras.log_model(model_bert, \"bert_model\")\n",
    "\n",
    "    # Ajouter le mod√®le au Model Registry\n",
    "    model_name = \"bert-classification\"\n",
    "    client = MlflowClient()\n",
    "    model_uri = f\"runs:/{run.info.run_id}/bert_model\"\n",
    "\n",
    "    try:\n",
    "        client.get_registered_model(model_name)\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        client.create_registered_model(model_name)\n",
    "\n",
    "    client.create_model_version(name=model_name, source=model_uri, run_id=run.info.run_id)\n",
    "\n",
    "    # Affichage des r√©sultats finaux\n",
    "    print(\"Test Accuracy:\", acc_bert)\n",
    "    print(\"Test F1 Score:\", f1_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R√©sultats Finaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LSTM Accuracy:\", acc_lstm, \"F1 Score:\", f1_lstm)\n",
    "print(\"BERT Accuracy:\", acc_bert, \"F1 Score:\", f1_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorisation parie en production.\n",
    "TEster USE et Word Embeding :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
