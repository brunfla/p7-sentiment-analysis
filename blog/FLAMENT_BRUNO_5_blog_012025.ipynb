{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison de trois approches d’analyse de tweets et démarche MLOps : Du modèle simple à BERT\n",
    "\n",
    "Dans cet article, nous allons explorer trois approches différentes pour analyser la polarité (sentiment) de tweets, puis décrire la démarche MLOps mise en œuvre pour automatiser, versionner et déployer ces modèles. Les trois méthodes dont nous parlerons sont :\n",
    "\n",
    "- Un modèle sur mesure simple : Régression Logistique avec vecteurs TF-IDF.\n",
    "- Un modèle sur mesure avancé : Réseau de neurones LSTM bidirectionnel (BiLSTM) utilisant des embeddings GloVe.\n",
    "- Un modèle avancé pré-entraîné : DistilBERT (via la librairie ktrain).\n",
    "\n",
    "Au fil de cet article, nous présenterons leurs spécificités, leur mise en œuvre et les éléments de comparaison. Nous détaillerons également la mise en place d’une démarche orientée MLOps (Machine Learning Operations), incluant le tracking expérimental, la gestion des versions, les tests, le déploiement, ainsi que le suivi de la performance en production avec un exemple d’utilisation d’Azure Application Insights.\n",
    "\n",
    "![dvc_stage_list](DVC_STAGE_LIST.png)\n",
    "\n",
    "## 1. Contexte et objectifs\n",
    "\n",
    "### 1.1 Pourquoi analyser la polarité de tweets ?\n",
    "\n",
    "Les plateformes de réseaux sociaux comme Twitter génèrent un volume considérable de données textuelles. L’analyse de sentiment consiste à déterminer si un tweet exprime une opinion positive, négative ou neutre, ce qui peut avoir de nombreuses applications : suivi de l’image de marque, détection d’opinion politique, satisfaction client, etc.\n",
    "\n",
    "### 1.2 Les grandes familles de modèles\n",
    "\n",
    "#### **Méthodes traditionnelles + TF-IDF**\n",
    "\n",
    "Les modèles comme la Régression Logistique ou le SVM restent souvent efficaces pour des tâches de classification sur des textes courts, d’autant plus lorsque la quantité de données est importante. Le TF-IDF (Term Frequency–Inverse Document Frequency) est un moyen classique de transformer du texte en vecteur numérique, en mettant en avant les termes les plus significatifs.\n",
    "\n",
    "#### **Réseaux de neurones avancés + Embeddings (Word2Vec, GloVe)**\n",
    "\n",
    "L’avènement du deep learning a permis de recourir à des représentations de mots plus riches, comme les embeddings GloVe (Global Vectors), qui capturent des similarités sémantiques. En particulier, les réseaux de neurones récurrents (RNN) et leurs variantes, notamment la LSTM bidirectionnelle, sont très populaires pour le traitement du langage naturel.\n",
    "\n",
    "#### **Transformers + Modèles pré-entraînés (BERT, DistilBERT, etc.)**\n",
    "\n",
    "Les Transformers ont révolutionné le traitement automatique du langage. Des modèles pré-entraînés tels que BERT, DistilBERT, GPT-2, etc., atteignent des performances élevées grâce à un entraînement sur de grands volumes de textes. DistilBERT est une version allégée de BERT, plus rapide à l’inférence et nécessitant moins de ressources.\n",
    "\n",
    "## 2. Aperçu du pipeline DVC\n",
    "\n",
    "![dvc_dag](DVC_DAG.png)\n",
    "\n",
    "\n",
    "Avant d’entrer dans le détail de chaque approche, il est important de comprendre le fonctionnement général du pipeline. Le fichier dvc.yaml comprend plusieurs étapes regroupées en trois grands blocs :\n",
    "\n",
    "- **Data Preparation** :\n",
    "    - Split des données en jeux d’entraînement, de validation et de test.\n",
    "    - Nettoyage et préparation des tweets pour leur utilisation avec TF-IDF et GloVe.\n",
    "    - Génération des vecteurs TF-IDF et GloVe.\n",
    "\n",
    "- **Train Model** :\n",
    "    - Entraînement du modèle de Régression Logistique sur TF-IDF.\n",
    "    - Entraînement de la LSTM bidirectionnelle sur embeddings GloVe.\n",
    "    - Entraînement du modèle DistilBERT (via la librairie ktrain).\n",
    "\n",
    "- **Test Model** :\n",
    "    - Tests de performance sur le jeu de test pour chacun des trois modèles.\n",
    "\n",
    "Enfin, une étape API gère la construction du conteneur Docker et le test de l’API.\n",
    "\n",
    "### 2.1 La version de données avec DVC\n",
    "\n",
    "DVC (Data Version Control) permet de :\n",
    "\n",
    "- Versionner de gros fichiers (corpus de tweets, embeddings, modèles entraînés) sans les stocker directement dans Git.\n",
    "- Maintenir la reproductibilité en associant chaque jeu de données ou chaque modèle à un hash spécifique.\n",
    "- Automatiser l’exécution du pipeline complet ou partiel dès qu’un changement est détecté dans le code ou dans les paramètres.\n",
    "\n",
    "***Le pipeline execute uniquement les parties du pipeline qui sont impacté par un changement***\n",
    "![dvc_repro](DVC_REPRO.png)\n",
    "\n",
    "## 3. Modèles développés et comparaison\n",
    "\n",
    "### 3.1 Modèle sur mesure simple : Régression Logistique + TF-IDF\n",
    "\n",
    "#### 3.1.1 Présentation\n",
    "\n",
    "Ce pipeline commence par :\n",
    "- Extraire les tweets bruts et créer un jeu d’entraînement, validation et test.\n",
    "- Nettoyer basiquement les tweets : suppression des URL, ponctuation superflue, symboles, etc.\n",
    "- Appliquer un vecteur TF-IDF sur l’ensemble d’entraînement.\n",
    "\n",
    "La Régression Logistique est ensuite entraînée pour classifier chaque tweet en polarité positive ou négative.\n",
    "\n",
    "#### 3.1.2 Avantages et inconvénients\n",
    "\n",
    "- Avantages :\n",
    "    - Rapidité d’entraînement et d’inférence.\n",
    "    - Besoin en ressources faible.\n",
    "    - Interprétabilité plus simple : on peut inspecter les coefficients associés à chaque mot.\n",
    "\n",
    "- Inconvénients :\n",
    "    - Capacité limitée à saisir la sémantique avancée.\n",
    "    - Sensible à des variations de vocabulaire (e.g., fautes d’orthographe, abréviations non prévues).\n",
    "\n",
    "#### 3.1.3 Performances\n",
    "\n",
    "Sur un jeu de tweets standard, la Régression Logistique avec TF-IDF peut atteindre une précision de l’ordre de 75-80 %. Les performances exactes varient selon la qualité du prétraitement et la taille du jeu de données.\n",
    "\n",
    "***test accurrency 0.76***\n",
    "![](MLFLOW_RL_TEST_ACC.png)\n",
    "\n",
    "### 3.2 Modèle sur mesure avancé : BiLSTM + GloVe\n",
    "\n",
    "#### 3.2.1 Présentation\n",
    "\n",
    "Dans cette deuxième approche, nous utilisons :\n",
    "\n",
    "- Des embeddings GloVe : chargés depuis un fichier externe (par exemple glove.twitter.27B.50d.txt).\n",
    "- Une architecture LSTM bidirectionnelle (BiLSTM) pour gérer les dépendances contextuelles dans le texte, aussi bien dans le sens direct que dans le sens inverse.\n",
    "\n",
    "#### 3.2.2 Avantages et inconvénients\n",
    "\n",
    "- Avantages :\n",
    "    - Les embeddings GloVe capturent des similarités sémantiques.\n",
    "    - La LSTM bidirectionnelle extrait mieux le contexte que les RNN classiques.\n",
    "\n",
    "- Inconvénients :\n",
    "    - Entraînement plus long que la Régression Logistique.\n",
    "    - Plus complexe à paramétrer (choix du nombre de neurones, etc.).\n",
    "    - Nécessite un prétraitement supplémentaire (tokenisation alignée avec GloVe, etc.).\n",
    "\n",
    "#### 3.2.3 Performances typiques\n",
    "\n",
    "Selon la taille de l’embedding (50, 100, 200 dimensions, etc.) et le nombre d’échantillons, on peut atteindre en général une précision de l’ordre de 80-85 %, voire davantage si le réseau est suffisamment entraîné et que la qualité des données est bonne.\n",
    "\n",
    "![Mlflow enregistre le model et les artifacts comme les plots](MLFLOW_LSTM_ARTIFACT.png)\n",
    "## 3.3 Modèle avancé pré-entraîné : DistilBERT via ktrain\n",
    "\n",
    "#### 3.3.1 Présentation\n",
    "\n",
    "La troisième approche s’appuie sur DistilBERT, un modèle de type Transformer pré-entraîné sur un vaste corpus de textes. Nous utilisons la bibliothèque ktrain pour :\n",
    "\n",
    "- Charger DistilBERT et ses poids pré-entraînés.\n",
    "- Adapter le modèle à notre jeu de tweets pour la classification binaire.\n",
    "\n",
    "(Commentaire : vous pourriez ajouter ici des extraits de code spécifiques à l’entraînement de DistilBERT avec la librairie ktrain.)\n",
    "\n",
    "#### 3.3.2 Avantages et inconvénients\n",
    "\n",
    "- Avantages :\n",
    "    - Excellentes performances, notamment pour détecter des nuances de langage.\n",
    "    - Nécessite moins de données annotées pour être performant, grâce au pré-entraînement.\n",
    "    - Possibilité de couvrir des expressions moins fréquentes ou du vocabulaire spécifique à Twitter.\n",
    "\n",
    "- Inconvénients :\n",
    "    - Temps d’inférence plus élevé qu’une simple régression logistique.\n",
    "    - Besoin de ressources GPU pour un entraînement fluide.\n",
    "    - Complexité plus grande, ce qui peut rendre l’interprétation du modèle plus délicate.\n",
    "\n",
    "#### 3.3.3 Performances typiques\n",
    "\n",
    "DistilBERT peut facilement atteindre et dépasser 85-90 % de précision, selon la qualité du jeu de données et la fine-tuning réalisé.\n",
    "\n",
    "## 4. La démarche MLOps\n",
    "### 4.1 Principes MLOps\n",
    "\n",
    "Le MLOps vise à industrialiser le cycle de vie d’un projet de Machine Learning, en reprenant les principes DevOps appliqués au développement logiciel classique :\n",
    "\n",
    "- Automatisation : Tests, intégration continue, déploiement continu (CI/CD).\n",
    "- Versioning : Pour le code, mais aussi pour les données, les modèles, les métriques.\n",
    "- Collaboration : Des équipes pluridisciplinaires (data scientists, développeurs, ops).\n",
    "- Monitoring & Observability : Suivi des performances en production, alertes en cas de dérive de données ou de baisse de performance.\n",
    "\n",
    "## 4.2 Tracking des expérimentations\n",
    "\n",
    "Dans ce projet, nous pouvons utiliser un outil comme MLflow pour suivre :\n",
    "\n",
    "- Les hyperparamètres (ex. : taille d’embedding, nombre d’époques, taux d’apprentissage).\n",
    "- Les métriques (accuracy, loss, etc.).\n",
    "- Les artefacts (modèles entraînés, courbes de validation).\n",
    "\n",
    "Chaque modèle produit un fichier mlflow_id.json dans le dossier de sortie, permettant de faire le lien avec la run associée dans MLflow.\n",
    "\n",
    "![](MLFLOW_ANALYSE.png)\n",
    "\n",
    "## 4.3 Stockage des modèles et gestion de versions\n",
    "\n",
    "- DVC se charge de gérer la version des gros fichiers (poids de la LSTM, du logistic model, etc.).\n",
    "- Git gère la version du code source.\n",
    "- MLflow conserve les détails de chaque expérience.\n",
    "\n",
    "Ainsi, il est possible de revenir à n’importe quelle version du pipeline, de reproduire les mêmes résultats et de comprendre quelle configuration a été utilisée.\n",
    "\n",
    "## 4.4 Tests unitaires et tests d’intégration\n",
    "\n",
    "Le pipeline inclut également des scripts de test pour chacun des modèles :\n",
    "\n",
    "- test_model_logistic.py\n",
    "- test_lstm_bidirectional_with_glove.py\n",
    "- test_model_distilbert_ktrain.py\n",
    "\n",
    "Ces scripts se chargent de charger le modèle, d’exécuter des prédictions sur un jeu de test et de sortir les métriques de performance. Intégrer ces tests dans un système de Continuous Integration (par exemple GitHub Actions, GitLab CI/CD ou Azure DevOps) garantit la fiabilité en cas de modification du code.\n",
    "\n",
    "![](DVC_STAGE_TEST.png)\n",
    "\n",
    "## 5. Déploiement et suivi en production\n",
    "\n",
    "### 5.1 Construction et test de l’API\n",
    "\n",
    "La dernière étape du pipeline (build_and_test_api) exécute un script shell build_and_test_api.sh qui :\n",
    "\n",
    "- Construit une image Docker à partir du Dockerfile.\n",
    "- Démarre un conteneur localement.\n",
    "- Exécute des tests automatisés (test_api.py) pour vérifier que l’API répond correctement.\n",
    "\n",
    "(Commentaire : vous pouvez insérer ici une capture d’écran de l’API en fonctionnement ou de l’outil de test type Postman / Swagger.)\n",
    "\n",
    "![](DOCKERFILE.png)\n",
    "\n",
    "## 5.2 Monitoring en production : Azure Application Insights\n",
    "\n",
    "Après le déploiement, il est essentiel de surveiller la performance du modèle en production. Azure Application Insights offre :\n",
    "\n",
    "- Collecte de logs : Temps de réponse, taux d’erreur, etc.\n",
    "- Suivi des métriques : Nombre de prédictions, utilisation des ressources.\n",
    "- Alertes personnalisées : Déclenchées si la latence dépasse un certain seuil, ou si le taux d’erreurs augmente.\n",
    "\n",
    "Pour aller plus loin :\n",
    "\n",
    "- Envoi des prédictions avec leur “label” final (dans le cas où on connaît la vérité terrain) à une base de données pour mesurer en continu la dérive (concept drift).\n",
    "- Analyse statistique : Comparaison régulière de la distribution des prédictions en production avec celle en phase de test.\n",
    "- Mise à jour automatique : Lorsqu’une dérive est détectée, un nouveau cycle d’entraînement peut être déclenché (si un jeu de données étiquetées est disponible).\n",
    "\n",
    "## 5.3 Approche d’amélioration continue\n",
    "\n",
    "L’idée est de boucler le cycle MLOps :\n",
    "\n",
    "- Collecte en continu de nouveaux tweets et de leurs labels réels (lorsqu’ils sont disponibles).\n",
    "- Analyse des nouvelles données pour comprendre si le modèle reste performant.\n",
    "- Entraînement itératif : réentraîner périodiquement le modèle avec DVC et MLflow, tout en gardant la traçabilité des versions.\n",
    "- Déploiement de la nouvelle version du modèle, suivi de tests et de monitoring continu.\n",
    "\n",
    "Cette démarche garantit que le modèle évolue avec la langue, les nouveaux hashtags ou expressions sur Twitter, et qu’il ne perde pas en pertinence au fil du temps.\n",
    "\n",
    "## 6. Comparaison finale et conclusion\n",
    "\n",
    "\n",
    "\n",
    "- Logistic Regression + TF-IDF : Un baseline efficace, rapide à entraîner et déployer. À privilégier pour des projets avec peu de ressources ou pour démarrer rapidement.\n",
    "\n",
    "- BiLSTM + GloVe : Un compromis équilibré pour capturer des aspects sémantiques plus riches que TF-IDF, sans la complexité totale d’un grand modèle Transformer.\n",
    "\n",
    "- DistilBERT : Offre la meilleure performance, surtout sur les nuances de langage, au prix d’une infrastructure plus lourde (GPU) et d’une complexité de mise en place plus importante.\n",
    "\n",
    "Sur le plan MLOps, le pipeline DVC démontre la possibilité de :\n",
    "\n",
    "- Versionner rapidement jeux de données et modèles.\n",
    "- Lancer un entraînement reproductible à chaque modification.\n",
    "- Traquer les expériences grâce à MLflow.\n",
    "- Déployer une API Docker prête à être testée et monitorée (par exemple via Azure Application Insights).\n",
    "\n",
    "L’ajout de tests unitaires et de tests d’intégration assure la robustesse du système à chaque mise à jour, tandis que le monitoring permet de suivre la dérive éventuelle en production et de redéclencher des entraînements si nécessaire. À terme, on peut imaginer un système entièrement automatisé (CI/CD) qui récupère de nouveaux tweets en continu, les étiquette, relance l’entraînement et déploie la nouvelle version du modèle, le tout en conservant un historique complet de chaque itération.\n",
    "\n",
    "7. Ressources supplémentaires\n",
    "\n",
    "- DVC (Data Version Control) : https://dvc.org/\n",
    "- MLflow : https://mlflow.org/\n",
    "- ktrain : https://github.com/amaiya/ktrain\n",
    "- Azure Application Insights : https://docs.microsoft.com/fr-fr/azure/azure-monitor/app/app-insights-overview\n",
    "\n",
    "## Mot de la fin\n",
    "\n",
    "En conclusion, l’utilisation d’une démarche MLOps structurée pour l’analyse de sentiments sur Twitter permet de répondre aux défis du versioning, de la reproductibilité et du déploiement rapide. Que vous optiez pour un modèle simple en Régression Logistique, une BiLSTM enrichie de GloVe ou un modèle Transformer pré-entraîné comme DistilBERT, la clé réside dans l’automatisation, la traçabilité et le monitoring en continu pour maintenir des performances fiables dans le temps."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
