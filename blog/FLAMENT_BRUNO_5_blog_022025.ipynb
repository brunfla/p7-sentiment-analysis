{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps : Quand le Machine Learning rencontre l‚Äôesprit du DevOps\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Les projets de Machine Learning (ML) sont souvent compar√©s √† des exp√©riences scientifiques : on explore, on teste, on ajuste. Une sorte de laboratoire o√π chaque id√©e est mise √† l‚Äô√©preuve. Mais cette approche, bien qu‚Äôefficace pour apprendre, montre vite ses limites quand il s‚Äôagit de passer √† la production.\n",
    "\n",
    "Avec des mod√®les plus complexes, plus de donn√©es, et des besoins de monitoring, il ne suffit plus que ¬´‚ÄØ√ßa marche dans le notebook‚ÄØ¬ª. C‚Äôest ici que le MLOps, inspir√© du DevOps, entre en jeu‚ÄØ: il structure, automatise et industrialise chaque √©tape d‚Äôun projet ML. Pour le d√©montrer, prenons un exemple concret‚ÄØavec un **projet d‚Äôanalyse de sentiments**. Il s'agit de cr√©er un prototype d'IA pour pr√©dire le sentiment des tweets √† partir de donn√©es open source et d√©ploy√© le model via une API Cloud.\n",
    "\n",
    "## 1) Premier pas\n",
    "\n",
    "L'une des premi√®res √©tapes est le choix du mod√®le, c'est une √©tape essentielle mais souvent complexe. Cela d√©pend des sp√©cificit√©s des donn√©es, des contraintes du projet et des objectifs vis√©s. Une approche pragmatique consiste √† commencer par un mod√®le simple, puis √† explorer des mod√®les de plus en plus avanc√©s.\n",
    "\n",
    "Pour notre projet d'analyse de sentiment, nous commen√ßons par **une r√©gression logistique**. Pourquoi‚ÄØ? Parce qu‚Äôelle est rapide, facile √† impl√©menter et souvent suffisante pour valider une id√©e. Avec cette m√©thode, nous avons utilis√© des caract√©ristiques textuelles de base, comme la fr√©quence des mots (bag of words). Cette **baseline** joue un double r√¥le‚ÄØ: elle permet de valider rapidement la faisabilit√© de l'approche et sert de r√©f√©rence pour √©valuer les am√©liorations apport√©es par des mod√®les plus complexes.\n",
    "\n",
    "Une fois que notre r√©gression logistique est en place et que nous avons une baseline, il devient crucial de structurer notre approche pour garantir la reproductibilit√© des r√©sultats, faciliter la comparaison des exp√©rimentations, et pr√©parer le mod√®le au d√©ploiement en production, ce que permettent les principes du MLOps et des outils comme **MLflow**. **MLflow** stocke les m√©tadonn√©es de run et les mod√®les, tout en assurant le suivi des exp√©rimentations.\n",
    "\n",
    "\n",
    "\n",
    "En ce qui concerne MLops, nous allons utiliser conjointement plusieurs outils :\n",
    "- **MLflow**: stocke les m√©tadonn√©es de run et les mod√®les.\n",
    "- **DVC**: stocke et versionne les datasets, sans multiplier l‚Äôespace √† chaque run. DVC est con√ßu pour g√©rer efficacement les changements et √©viter de t√©l√©charger ou de pousser inutilement des donn√©es si elles n'ont pas √©t√© modifi√©es.\n",
    "- **Git**: stocke les scripts, configurations et fichiers .dvc n√©cessaires pour synchroniser code et donn√©es, assurant une tra√ßabilit√© compl√®te du projet.\n",
    "- **Docker/Conda**: Garantie d'avoir un environnement reproductible. \n",
    "    - ex : conda pack -n mlops-env -o mlops-env.tar.gz && docker build -f Dockerfile.mlops-env -t mlops-env:v1 .\n",
    "\n",
    "Ensemble, ces outils cr√©ent un √©cosyst√®me int√©gr√© qui garantit la reproductibilit√© des r√©sultats en synchronisant chaque version du code, des donn√©es et des mod√®les. Ils facilitent √©galement la collaboration entre √©quipes en offrant un suivi clair des exp√©rimentations et des changements, tout en structurant des pipelines de Machine Learning robustes et facilement d√©ployables √† l'√©chelle.\n",
    "\n",
    "\n",
    "\n",
    "### Points cl√©s :\n",
    "- Utilisation de Docker\n",
    "- L'utilisation de DVC et git permet de faire en sorte que le script \n",
    "- l'utilisation d'Hydra permet de changer de passer d'une exp√©rience √† autre simplement.\n",
    "\n",
    "### R√©sultats :\n",
    "Voici les performances obtenues sur notre dataset‚ÄØ:\n",
    "- Pr√©cision : 76,5%\n",
    "- F1-score : 74,2%\n",
    "\n",
    "## Cr√©ation du pipeline avec DVC (Data Version Control)\n",
    "\n",
    "Dans un pipeline DevOps classique, vous codez, vous poussez sur Git, et boum, tout se construit et se d√©ploie automatiquement. En MLOps, on va un cran plus loin, les √©tapes classiques sont : \n",
    "- Pr√©parer les donn√©es (nettoyage, enrichissement).\n",
    "- Entra√Æner les mod√®les (et tester plusieurs configurations).\n",
    "- Valider les r√©sultats (cross-validation, ensembles de test).\n",
    "- Et ensuite‚ÄØ? Surveiller en continu. Parce qu‚Äôun mod√®le, contrairement √† du code, peut se d√©grader avec le temps !(drift)\n",
    "\n",
    "En machine learning, les pipelines impliquent non seulement du code, mais aussi des donn√©es, des mod√®les, et des √©tapes de transformation interconnect√©es. C'est l√† que DVC devient un outil indispensable. Inspir√© de Git, DVC d√©tecte automatiquement les changements dans votre pipeline, ne r√©ex√©cutant que les √©tapes n√©cessaires pour garantir une gestion efficace et reproductible des workflows ML.\n",
    "\n",
    "\n",
    "## Monter en puissance avec des mod√®les avanc√©s\n",
    "\n",
    "Bien que ce soit un bon point de d√©part, le mod√®le manque de finesse pour capturer des relations contextuelles. Pour am√©liorer les r√©sultats, nous avons besoin de tester des mod√®les plus avanc√©s, comme des word embeddings combin√©s √† des r√©seaux neuronaux (CNN ou RNN). Ces approches permettent de mieux comprendre le contexte des mots en tenant compte des s√©quences.\n",
    "\n",
    "Avec Hydra, il devient facile d'ajouter des configurations sans trop toucher aux scripts python.\n",
    "\n",
    "Capture d‚Äô√©cran des r√©sultats et du graphe des erreurs communes.\n",
    "\n",
    "R√©sultat avec un CNN :\n",
    "- Pr√©cision : 82,7%\n",
    "- F1-score : 81,4%\n",
    "\n",
    "Cette am√©lioration montre que le mod√®le capture d√©sormais des nuances plus subtiles dans les sentiments. Cependant, la complexit√© augmente : le mod√®le prend plus de temps √† entra√Æner, et le suivi des hyperparam√®tres devient critique.\n",
    "\n",
    "Capture d‚Äô√©cran des r√©sultats compar√©s aux erreurs de la r√©gression logistique.\n",
    "\n",
    "## √âtape 3 : L‚Äô√âtat de l‚Äôart avec BERT\n",
    "\n",
    "Enfin, nous avons utilis√© BERT, un mod√®le pr√©entra√Æn√© d‚Äô√âtat de l‚Äôart, capable de comprendre les subtilit√©s linguistiques et les relations complexes dans les phrases. Avec BERT, les r√©sultats ont √©t√© impressionnants :\n",
    "\n",
    "R√©sultat avec BERT :\n",
    "- Pr√©cision : 89,5%\n",
    "- F1-score : 88,9%\n",
    "\n",
    "Cependant, l‚Äôutilisation de BERT a introduit de nouveaux d√©fis‚ÄØ:\n",
    "- Temps d‚Äôentra√Ænement prolong√© : Il a fallu 10 fois plus de temps que pour la r√©gression logistique.\n",
    "- Infrastructure n√©cessaire : L‚Äôentra√Ænement a n√©cessit√© un GPU, et le suivi des versions de donn√©es et de mod√®les est devenu encore plus crucial.\n",
    "\n",
    "Capture d‚Äô√©cran des r√©sultats, avec une visualisation des pr√©dictions BERT sur des exemples complexes.\n",
    "\n",
    "## Passage en production avec MLOps\n",
    "\n",
    "√Ä chaque √©tape, les mod√®les deviennent plus performants, mais aussi plus complexes √† g√©rer. C‚Äôest ici que le MLOps prend tout son sens. Voici comment il a structur√© notre projet‚ÄØ:\n",
    "\n",
    "### 1. Suivi des exp√©rimentations\n",
    "\n",
    "Gr√¢ce √† des outils comme MLflow, nous avons enregistr√© chaque exp√©rimentation‚ÄØ:\n",
    "- Version des donn√©es utilis√©es.\n",
    "- Hyperparam√®tres et configurations des mod√®les.\n",
    "- Performances obtenues (pr√©cision, F1-score, etc.).\n",
    "\n",
    "Cela nous a permis de comparer les r√©sultats facilement et de justifier nos choix √† chaque √©tape.\n",
    "\n",
    "### 2. Automatisation des pipelines\n",
    "\n",
    "Nous avons automatis√© les √©tapes cl√©s‚ÄØ:\n",
    "- Pr√©paration des donn√©es (nettoyage, transformation).\n",
    "- Entra√Ænement des mod√®les avec diff√©rentes configurations.\n",
    "- Validation sur des ensembles ind√©pendants.\n",
    "\n",
    "Un outil comme Kubeflow nous a aid√©s √† orchestrer ces t√¢ches et √† les rendre reproductibles.\n",
    "\n",
    "### 3. Monitoring en production\n",
    "\n",
    "Une fois BERT d√©ploy√©, un syst√®me de monitoring a √©t√© mis en place pour surveiller les performances en temps r√©el. Par exemple‚ÄØ:\n",
    "- D√©tection des drifts de donn√©es‚ÄØ: Si les avis clients √©voluent (argot, emojis, etc.).\n",
    "- Suivi des m√©triques‚ÄØ: Si le mod√®le perd en pr√©cision ou en rappel.\n",
    "\n",
    "Conclusion : Apprendre, structurer, et industrialiser\n",
    "\n",
    "L‚Äôhistoire de ce projet d‚Äôanalyse de sentiments montre bien la double nature des projets ML. D‚Äôun c√¥t√©, il y a l‚Äôaspect exploratoire‚ÄØ: tester diff√©rents mod√®les et approches pour trouver ce qui fonctionne. De l‚Äôautre, il y a le besoin d‚Äôindustrialisation, o√π la reproductibilit√© et la fiabilit√© deviennent essentielles.\n",
    "\n",
    "Le MLOps, en s‚Äôappuyant sur les principes du DevOps, nous a permis de structurer cette transition. Il a transform√© une s√©rie d‚Äôexp√©rimentations en une solution robuste, pr√™te pour la production. Et √† chaque √©tape, il nous a offert des outils pour g√©rer la complexit√© croissante du Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps : Construire des mod√®les qui tiennent la distance\n",
    "\n",
    "D√©velopper un projet de machine learning suit g√©n√©ralement un parcours bien d√©fini : collecte et pr√©paration des donn√©es, exp√©rimentation et entra√Ænement des mod√®les, √©valuation des performances, puis mise en production. Chaque √©tape apporte son lot de d√©fis techniques et m√©thodologiques, mais avec une bonne organisation, il est possible d‚Äôobtenir un mod√®le performant et exploitable.\n",
    "\n",
    "Cependant, √† mesure que le projet √©volue et prend de l‚Äôampleur, de nouvelles contraintes apparaissent. Comment garantir que le mod√®le reste performant dans le temps ? Comment assurer la reproductibilit√© des r√©sultats ? Comment maintenir un cadre structur√© malgr√© l‚Äô√©volution des donn√©es, des infrastructures ou des √©quipes ?\n",
    "\n",
    "C‚Äôest ici que MLOps intervient. Son r√¥le est de structurer et fiabiliser le cycle de vie des mod√®les en anticipant ces d√©fis avant qu‚Äôils ne deviennent des freins majeurs. Il permet d‚Äôassurer la tra√ßabilit√©, la reproductibilit√© et l‚Äô√©volutivit√© des mod√®les, ind√©pendamment des changements qui surviennent au fil du temps. Plut√¥t que de simplement optimiser la vitesse de mise en production, MLOps vise √† garantir une progression stable et ma√Ætris√©e, en r√©duisant les risques li√©s aux infrastructures, aux donn√©es et √† la gouvernance.\n",
    "\n",
    "L√† o√π un projet ML peut devenir difficile √† maintenir sur le long terme, MLflow et DVC apportent des solutions concr√®tes :\n",
    "\n",
    "- MLflow centralise le suivi des exp√©rimentations et la gestion des mod√®les, facilitant leur versioning et leur √©valuation.\n",
    "- DVC assure une gestion efficace des donn√©es et des pipelines, garantissant la reproductibilit√© des entra√Ænements et des r√©sultats.\n",
    "\n",
    "Ces outils permettent non seulement de structurer le travail, mais aussi d‚Äô√©viter la d√©pendance aux individus, en garantissant que chaque avanc√©e est document√©e et exploitable par toute l‚Äô√©quipe, m√™me apr√®s plusieurs mois d‚Äôinactivit√© sur le projet.\n",
    "\n",
    "üí° Pour illustrer ces b√©n√©fices concrets, nous prendrons l‚Äôexemple d‚Äôune analyse de sentiments bas√©e sur des tweets. Ce projet nous servira de fil conducteur pour montrer comment MLflow, DVC et Docker/Kubernetes r√©pondent aux d√©fis techniques et organisationnels tout au long du cycle de vie d‚Äôun mod√®le. De la gestion des donn√©es √† la mise en production, chaque √©tape sera explor√©e sous l‚Äôangle du MLOps, afin de d√©montrer comment cette approche s‚Äôimpose aujourd‚Äôhui comme un levier strat√©gique pour garantir la p√©rennit√© et la scalabilit√© des solutions d‚Äôintelligence artificielle.\n",
    "\n",
    "## Analyse exploratoire des donn√©es (AED)\n",
    "\n",
    "\n",
    "| **Composant MLOps** | **Solution sans MLOps** | **Probl√®me potentiel √† long terme** | **Solution MLOps** | **Outil** |\n",
    "|----------------------|----------------------|----------------------|----------------------|----------------------|\n",
    "| **Analyse exploratoire des donn√©es (AED)** | Analyse et visualisation ponctuelle des donn√©es via des notebooks | Pas de tra√ßabilit√© des transformations appliqu√©es, difficult√© √† reproduire l‚Äôanalyse | Versionner les transformations et standardiser le pr√©processing | **DVC** (versionning des donn√©es), **MLflow** (tracking des exp√©riences) |\n",
    "| **Pr√©paration des donn√©es et extraction de caract√©ristiques** | Nettoyage et transformation des donn√©es manuellement, stockage en local ou sur un drive | Incoh√©rence des datasets entre √©quipes, difficult√© √† reproduire les jeux de donn√©es | Versionnement des donn√©es et pipelines reproductibles | **DVC** (gestion des datasets), **MLflow** (enregistrement des transformations) |\n",
    "| **Entra√Ænement et r√©glage du mod√®le** | Exp√©rimentations non structur√©es dans des notebooks, hyperparam√®tres ajust√©s manuellement | Perte des versions interm√©diaires des mod√®les, pas de reproductibilit√© des exp√©riences | Tracking des entra√Ænements, gestion des hyperparam√®tres, reproductibilit√© | **MLflow** (Tracking, Model Registry), **DVC** (pipelines de traitement) |\n",
    "| **Revue et gouvernance du mod√®le** | Validation et revue manuelle des mod√®les, crit√®res de qualit√© non formalis√©s | Risque de biais non d√©tect√©s, mod√®les non conformes aux normes r√©glementaires | Automatisation des tests de validation, auditabilit√© des mod√®les | **MLflow** (validation et audit des mod√®les), **DVC** (tra√ßabilit√© des donn√©es) |\n",
    "| **Inf√©rence et d√©ploiement du mod√®le** | D√©ploiement manuel via scripts, mod√®le stock√© sans versioning | Risque d‚Äôerreurs de configuration, difficult√© √† restaurer une version stable | Automatisation du packaging et du d√©ploiement, versionnement des mod√®les | **MLflow** (Model Registry, Serving), **Docker/Kubernetes** (d√©ploiement scalable) |\n",
    "| **Surveillance des mod√®les** | Pas de monitoring, ou v√©rification manuelle des pr√©dictions | D√©gradation des performances non d√©tect√©e, mod√®le obsol√®te face √† de nouvelles donn√©es | Monitoring automatique des performances et d√©tection du drift | **MLflow** (Model Monitoring), **Prometheus/Grafana** (visualisation des m√©triques) |\n",
    "| **R√©entra√Ænement automatis√© du mod√®le** | R√©entra√Ænement manuel, sans d√©clenchement bas√© sur des crit√®res pr√©cis | Mod√®le vieillissant, performance en baisse, absence de mise √† jour proactive | D√©clenchement du r√©entra√Ænement automatique bas√© sur des m√©triques pr√©d√©finies | **MLflow** (gestion des mod√®les), **DVC** (pipelines automatis√©s) |\n",
    "\n",
    "\n",
    "## Cycle de vie\n",
    "\n",
    "## MLflow : Le carnet de bord des exp√©rimentations ML\n",
    "\n",
    "(# Ici, vous pouvez ins√©rer une capture d'√©cran MLflow ou un court code montrant l'utilisation de mlflow.start_run(), mlflow.log_param(), mlflow.log_metric()...)\n",
    "\n",
    "L'une des premi√®res √©tapes dans un projet ML est le choix du mod√®le. Cette √©tape essentielle est souvent complexe et d√©pend autant des sp√©cificit√©s des donn√©es que des contraintes du projet et des objectifs vis√©s. Pour d√©marrer, il est judicieux de commencer par un mod√®le simple, puis d‚Äôexplorer des mod√®les plus avanc√©s. Dans notre cas, nous avons opt√© pour une r√©gression logistique. Pourquoi‚ÄØ? Parce qu‚Äôelle est rapide, facile √† impl√©menter et dsouvent suffisante pour valider la faisabilit√© de l‚Äôapproche. Ce mod√®le, que l‚Äôon nomme baseline, joue un double r√¥le :\n",
    "- Confirmer rapidement la validit√© de la d√©marche.\n",
    "- Servir de r√©f√©rence pour √©valuer les gains apport√©s par des mod√®les plus sophistiqu√©s.\n",
    "\n",
    "### Capturer les m√©triques\n",
    "\n",
    "Dans le cadre de ce projet d‚Äôanalyse de sentiments, la baseline (r√©gression logistique) est enregistr√©e dans le Model Registry de MLflow, ce qui offre un suivi centralis√© de ses performances.\n",
    "Comparaison de la baseline avec un mod√®le plus avanc√©\n",
    "\n",
    "Lorsque de nouveaux mod√®les sont test√©s (par exemple un r√©seau de neurones), MLflow facilite la comparaison avec la baseline, tant au niveau des m√©triques que des hyperparam√®tres utilis√©s. Un simple coup d‚Äô≈ìil √† l‚Äôinterface permet de voir si le nouveau mod√®le surpasse ou non la baseline initiale.\n",
    "\n",
    "##  Un pipeline unique ou plusieurs ?\n",
    "\n",
    "(# Rajouter √©ventuellement un bref aper√ßu YAML/Hydra montrant comment vous param√©trez le vectoriseur et le mod√®le.)\n",
    "\n",
    "Cependant, la baseline n‚Äôest qu‚Äôun point de d√©part : √† mesure que l‚Äôon it√®re, que l‚Äôon ajuste les hyperparam√®tres et que l‚Äôon √©value diff√©rents mod√®les, il devient primordial de garder une tra√ßabilit√© pr√©cise de chaque exp√©rimentation. Dans notre projet, nous souhaitions par exemple tester plusieurs vectoriseurs (TF-IDF, GloVe, BERT‚Ä¶), diff√©rents mod√®les (r√©gression logistique, LSTM, Random Forest, etc.) ou encore des configurations vari√©es (batch_size, lr, seuils de d√©coupage des donn√©es, etc.).\n",
    "\n",
    "Pour √©viter de multiplier les scripts et de rendre la maintenance laborieuse, on s‚Äôappuie sur un pipeline modulaire et param√©trable. Na√Øvement, deux approches sont possibles :\n",
    "- Dupliquer le pipeline pour chaque variante,\n",
    "- Cr√©er un pipeline modulaire et param√©trable, o√π la vectorisation, le mod√®le ou les hyperparam√®tres sont g√©r√©s via un syst√®me de configuration (ex. Hydra, YAML, etc.).\n",
    "\n",
    "La premi√®re approche peut para√Ætre simple mais devient vite co√ªteuse en maintenance et en risques de divergence de code (copies multiples). Le guide Google ‚ÄúContinuous delivery and automation pipelines in machine learning‚Äù (souvent cit√© comme une r√©f√©rence MLOps) pr√©conise ainsi :\n",
    "\n",
    "    ‚ÄúTo reduce complexity and promote reuse, we recommend building modular and parametric pipelines. Each stage (data processing, training, evaluation) is defined once and can be reused by multiple variants or parameter sets. This avoids duplication of code and simplifies maintenance.‚Äù\n",
    "\n",
    "En d‚Äôautres termes, un pipeline modulaire et param√©trable reste plus souple, plus facile √† tester et √† maintenir, tout en assurant la tra√ßabilit√© au sein d‚Äôune m√™me structure de code. Gr√¢ce √† une configuration centralis√©e, vous n‚Äôavez qu‚Äô√† adapter quelques param√®tres pour changer de vectoriseur ou de mod√®le, ce qui acc√©l√®re consid√©rablement l‚Äôexp√©rimentation et limite les erreurs.\n",
    "\n",
    "### CI/CD Github\n",
    "(# Rajoutez une courte phrase expliquant ce qu‚Äôon voit dans la capture d‚Äô√©cran, par ex. ‚ÄúCi-dessous un exemple de workflow GitHub Actions d√©clench√© √† chaque push, qui ex√©cute nos tests et notre pipeline MLOps.‚Äù)\n",
    "Capture d'√©cran\n",
    "\n",
    "## Passage en production\n",
    "\n",
    "(# Ici, vous pouvez mentionner comment vous packagez le mod√®le, par exemple via Docker. Ou comment vous utilisez un orchestrateur type Kubernetes, ou un service. Expliquer tr√®s bri√®vement la d√©marche.)\n",
    "\n",
    "Apr√®s avoir valid√© un mod√®le satisfaisant, il faut le d√©ployer pour qu‚Äôil soit accessible en production. Cette √©tape peut impliquer :\n",
    "- La containerisation (via Docker) pour embarquer le mod√®le et son environnement d‚Äôex√©cution,\n",
    "- Le d√©ploiement sur un cluster Kubernetes ou un service d‚Äôh√©bergement (AWS, GCP, Azure‚Ä¶),\n",
    "- La mise en place d‚Äôune API (REST, gRPC) permettant de recevoir des donn√©es et de retourner des pr√©dictions,\n",
    "- Des scripts ou workflows CI/CD (GitHub Actions, GitLab CI, Jenkins‚Ä¶) assurant que chaque nouvelle version du mod√®le est correctement test√©e et livr√©e.\n",
    "\n",
    "(# Ajouter un exemple rapide : ‚ÄúNous avons cr√©√© un Dockerfile d√©crivant l‚Äôenvironnement, qui inclut Python 3.X, scikit-learn, MLflow, etc. Ensuite, un script de d√©ploiement‚Ä¶‚Äù)\n",
    "DVC et MLflow : Un duo pour une gestion coh√©rente des mod√®les et des donn√©es\n",
    "\n",
    "Apr√®s avoir d√©fini une baseline et explor√© des mod√®les plus avanc√©s, la gestion des donn√©es et des versions devient essentielle. Il ne suffit pas de versionner les mod√®les avec MLflow ou les donn√©es avec DVC, mais de garantir un lien explicite entre les deux. Cette association assure que chaque modification repose sur un environnement tra√ßable et reproductible, une pierre angulaire du MLOps.\n",
    "\n",
    "Prenons un exemple concret : reprendre un mod√®le tagu√© en pr√©production dans MLflow, restaurer son environnement exact, et cr√©er une nouvelle branche Git pour pr√©parer une mise √† jour.\n",
    "```bash\n",
    "# R√©cup√©rer le hash Git depuis MLflow\n",
    "mlflow models describe -m \"models:/sentiment-analysis-baseline/Production\" > model_metadata.txt\n",
    "GIT_COMMIT=$(grep \"git_commit\" model_metadata.txt | awk -F': ' '{print $2}')\n",
    "\n",
    "# Restaurer l'environnement\n",
    "git checkout $GIT_COMMIT\n",
    "dvc checkout\n",
    "dvc pull\n",
    "```\n",
    "\n",
    "(# Expliquer en quelques mots ce qui se passe dans le script. ‚Äúmlflow models describe...‚Äù r√©cup√®re le commit Git associ√© au mod√®le, on fait ensuite git checkout pour retrouver le code, dvc checkout et dvc pull pour synchroniser les donn√©es.‚Äù)\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "(# Vous pouvez illustrer comment le monitoring ou la d√©rive de donn√©es peut √™tre d√©tect√©, ou simplement raccourcir √† votre convenance.)\n",
    "\n",
    "En d√©finitive, l‚Äôapproche MLOps va bien au-del√† du simple ¬´‚ÄØ√ßa marche dans le notebook‚ÄØ¬ª. En outillant chaque √©tape (tracking des exp√©riences, versioning des donn√©es, CI/CD et d√©ploiement), elle garantit tra√ßabilit√©, collaboration et industrialisation. Dans l‚Äôexemple de l‚Äôanalyse de sentiments, l‚Äôapproche modulaire et param√©trable permet d‚Äôit√©rer rapidement sur diff√©rents mod√®les ou configurations sans perdre le fil. R√©sultat‚ÄØ: on allie la vitesse d‚Äôexploration scientifique √† la fiabilit√© d‚Äôun environnement de production, assurant la p√©rennit√© et l‚Äôimpact des projets ML.\n",
    "\n",
    "(# Pensez √† ajouter √©ventuellement un glossaire de termes techniques ou un court paragraphe ‚ÄúAller plus loin‚Äù listant des liens officiels : MLflow, DVC, Hydra, Docker, etc. Cela peut aussi am√©liorer la lisibilit√© et l‚Äôenrichissement pour le lecteur.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
